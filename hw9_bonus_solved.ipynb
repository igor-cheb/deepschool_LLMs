{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install trl peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DPO - 10 –±–∞–ª–ª–æ–≤\n",
        "–î–∞–≤–∞–π—Ç–µ –æ–±—É—á–∏–º –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å—é DPO. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–º –Ω—É–∂–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç –ø—Ä—Ñ–µ–µ—Ä–Ω—Ü–∏–π - –Ω–∞–º –Ω—É–∂–µ–Ω –Ω–µ–∫–∏–π –ø—Ä–µ—Ñ–∏–∫—Å (–∑–∞–¥–∞—á–∞) –∏ —Ö–æ—Ä–æ—à–∏–π –∏ –ø–ª–æ—Ö–∏–µ –æ—Ç–≤–µ—Ç—ã.\n",
        "\n",
        "–í –∫–∞—á–µ—Å–≤–µ –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å - SmolLM –æ—Ç huggingface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROMPT\n",
            "<|im_start|>user\n",
            "what is the weather like today<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "Generated answer\n",
            "What a great question! Today's weather is a fascinating topic. Here's a summary of the current weather conditions:\n",
            "\n",
            "**Temperature:**\n",
            "\n",
            "* The temperature is currently around 22¬∞\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "checkpoint = \"HuggingFaceTB/SmolLM-360M-Instruct\"\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"what is the weather like today\"}]\n",
        "prompt_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
        "print(\"PROMPT\")\n",
        "print(prompt_text)\n",
        "inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
        "for k, v in inputs.items():\n",
        "    inputs[k] = v.to(device)\n",
        "\n",
        "gens = model.generate(**inputs)\n",
        "print(\"Generated answer\")\n",
        "print(tokenizer.decode(gens[0, inputs[\"input_ids\"].size(1):].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–ö–∞–∫ –º—ã –≤–∏–¥–∏–º —É –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å —Å–≤–æ–π prompt_format –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–Ω–∞ –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç - –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ –æ—Ç–≤–µ—á–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å.\n",
        "\n",
        "–ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º, —á—Ç–æ –Ω–∞—à–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∏–º–µ—é—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –Ω–∞—à–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏: –µ—Å–ª–∏ –∏–º –Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è –æ—Ç–≤–µ—Ç, –æ–Ω–∏ –º–æ–≥—É—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π. –ò–Ω–æ–≥–¥–∞ –º—ã –¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –¥–≤–∞ –æ—Ç–≤–µ—Ç–∞ –∏ –ø—Ä–æ—Å–∏–º –≤—ã–±—Ä–∞—Ç—å —Ç–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –±–æ–ª—å—à–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è. –¢–∞–∫–æ–µ –º–æ–∂–Ω–æ –∑–∞—á–∞—Å—Ç—É—é –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –Ω–∞–ø—Ä–∏–º–µ—Ä —É OpenAI.\n",
        "\n",
        "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –¥–∞—Ç–∞—Å–µ—Ç `HumanLLMs/Human-Like-DPO-Dataset` - —ç—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –ø–∞—Ä –æ—Ç–≤–µ—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä–æ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π (chosen) –æ—Ç–≤–µ—Ç –±–æ–ª–µ–µ \"—á–µ–ª–æ–≤–µ—á–Ω—ã–π\", —Ç–æ –µ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ —Å–µ–±–µ —Å–º–∞–π–ª–∏–∫–∏, –ª–µ–≥–∫–æ–º—ã—Å–ª–∏–µ, –∞ –º–µ–Ω–µ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π (rejected) –æ—Ç–≤–µ—Ç.\n",
        "–ö–∞–∫ –≤—ã –ø–æ–º–Ω–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è DPO –∏–º–µ–Ω–Ω–æ —Ç–∞–∫ –∏ —Å—Ç—Ä–æ—è—Ç—Å—è - –µ—Å—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–º–ø—Ç (–≤–æ–∑–º–æ–∂–Ω–æ, –∏—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —à–∞–≥–æ–≤) –∏ 2 –æ—Ç–≤–µ—Ç–∞, –æ–¥–∏–Ω –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Ö–æ—Ä–æ—à–∏–π, –∞ –¥—Ä—É–≥–æ–π - –ø–ª–æ—Ö–æ–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is \"\n",
            "           'it a funny cat or a ridiculous situation? Spill the beans! ü§£',\n",
            " 'prompt': 'Oh, I just saw the best meme - have you seen it?',\n",
            " 'rejected': \"I'm an artificial intelligence language model, I don't have \"\n",
            "             'personal experiences or opinions. However, I can provide you '\n",
            "             'with information on highly-rated and critically acclaimed films, '\n",
            "             'as well as recommendations based on specific genres or themes. '\n",
            "             'Would you like me to suggest some notable movies or discuss a '\n",
            "             'particular genre of interest?'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "dataset = load_dataset(\"HumanLLMs/Human-Like-DPO-Dataset\")\n",
        "\n",
        "pprint(dataset[\"train\"][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'chosen': \"You know, I think I'm a little bit of both, to be honest! I love \"\n",
            "           \"the energy and anonymity of a big city ‚Äì there's always something \"\n",
            "           'going on, and you can find pretty much anything you need at any '\n",
            "           'hour. But at the same time, I appreciate the charm and sense of '\n",
            "           \"community that comes with a small town. There's something really \"\n",
            "           'cozy about knowing your neighbors and being able to walk down Main '\n",
            "           'Street and run into friends.\\n'\n",
            "           '\\n'\n",
            "           \"That being said, if I'm being completely honest, I'm a bit of a \"\n",
            "           'sucker for a good mountain town. You know, the kind of place with '\n",
            "           \"a cute downtown area, surrounded by trails and mountains? That's \"\n",
            "           'my happy place! What about you, do you have a preference?',\n",
            " 'prompt': 'Are you more of a city person or a small-town fan?',\n",
            " 'rejected': \"As a professional AI, I don't possess personal preferences or \"\n",
            "             'engage in leisure activities. My purpose is to provide accurate '\n",
            "             'and informative responses to your inquiries, and I do not '\n",
            "             'experience downtime or personal experiences. My focus is solely '\n",
            "             'on assisting users with their queries to the best of my '\n",
            "             \"abilities. If you have any specific questions or topics you'd \"\n",
            "             \"like to discuss, I'm here to provide information and insights.\"}\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset(\"HumanLLMs/Human-Like-DPO-Dataset\", split=\"train[:10%]\")\n",
        "eval_dataset = load_dataset(\"HumanLLMs/Human-Like-DPO-Dataset\", split=\"train[10%:12%]\")\n",
        "\n",
        "pprint(eval_dataset[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º, —á—Ç–æ –Ω–∞—à–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–∏—Å–ª–∞–ª–∏ –Ω–∞–º —Ç–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –º—ã —Ö–æ—Ç–∏–º —Å–¥–µ–ª–∞—Ç—å –Ω–∞—à—É –º–æ–¥–µ–ª—å –ª—É—á—à–µ. –ú—ã –º–æ–∂–µ–º –Ω–∞–ø—Ä—è–º—É—é –ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏–∞ –Ω–∞ —Ö–æ—Ä–æ—à–∏—Ö —Å—ç–º–ø–ª–∞—Ö, –Ω–æ –º—ã –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–¥–∞—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –±–æ–ª–µ–µ –±–æ–≥–∞—Ç—ã–π —Å–∏–≥–Ω–∞–ª: –º—ã –Ω–µ —Ç–æ–ª—å–∫–æ —Ö–æ—Ç–∏–º –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å chosen —Ç–µ–∫—Å—Ç–∞, –Ω–æ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ö–æ—Ç–∏–º –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å rejected —Ç–µ–∫—Å—Ç–∞. –ß—Ç–æ–±—ã –µ—â–µ —Å–∏–ª—å–Ω–µ–µ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã, –¥–∞–≤–∞–π—Ç–µ –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ, –≥–¥–µ –≤ chosen –µ—Å—Ç—å —Å–º–∞–π–ª–∏–∫, –∞ –≤ rejected –µ–≥–æ –Ω–µ—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "emoji_pattern = re.compile(\n",
        "    '['\n",
        "    '\\U0001F600-\\U0001F64F'  # Emoticons\n",
        "    '\\U0001F300-\\U0001F5FF'  # Symbols & Pictographs\n",
        "    '\\U0001F680-\\U0001F6FF'  # Transport & Map Symbols\n",
        "    '\\U0001F700-\\U0001F77F'  # Alchemical Symbols\n",
        "    '\\U0001F780-\\U0001F7FF'  # Geometric Shapes Extended\n",
        "    '\\U0001F800-\\U0001F8FF'  # Supplemental Arrows-C\n",
        "    '\\U0001F900-\\U0001F9FF'  # Supplemental Symbols and Pictographs\n",
        "    '\\U0001FA00-\\U0001FA6F'  # Chess Symbols\n",
        "    '\\U0001FA70-\\U0001FAFF'  # Symbols and Pictographs Extended-A\n",
        "    '\\U00002702-\\U000027B0'  # Dingbats\n",
        "    '\\U000024C2-\\U0001F251'  # Enclosed characters\n",
        "    '\\U0000200D'             # Zero Width Joiner\n",
        "    '\\U0001F1E0-\\U0001F1FF'  # Flags\n",
        "    ']+', \n",
        "    re.UNICODE\n",
        ")\n",
        "\n",
        "def find_emojis(sample):\n",
        "    return bool(emoji_pattern.findall(sample[\"chosen\"])) and not bool(emoji_pattern.findall(sample[\"rejected\"]))\n",
        "\n",
        "train_dataset = train_dataset.filter(find_emojis)\n",
        "assert len(train_dataset) == 1061\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–ù–∞—à —Ç—Ä–µ–Ω–µ—Ä DPOTrainer –±—É–¥–µ—Ç —Å–æ–±–∏—Ä–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –ø–æ–ª–µ–π prompt, chosen –∏ rejected. –ß—Ç–æ–±—ã –≤—Å–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–æ—Å—å, –Ω–∞–º –Ω—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å chat_template –∫ –Ω–∞—à–∏–º –ø—Ä–∏–º–µ—Ä–∞–º. –¢–∞–∫ –∫–∞–∫ —É –Ω–∞—Å –¥–æ–≤–æ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ–π —Å–ª—É—á–∞–π —Å –¥–∏–∞–ª–æ–≥–æ–º –∏–∑ –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞ (–æ–¥–Ω–∞ –ø–∞—Ä–∞ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç), –º—ã –º–æ–∂–µ–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å chat_template –∫ prompt. –î–æ–±–∞–≤–ª—è—Ç—å EOS —Ç–æ–∫–µ–Ω –≤ chosen/rejected –Ω–µ –Ω—É–∂–Ω–æ, —ç—Ç–æ –¥–µ–ª–∞–µ—Ç –∑–∞ –Ω–∞—Å DPOTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_chat_template(sample, tokenizer):\n",
        "    messages = [{\"role\": \"user\", \"content\": sample[\"prompt\"]}]\n",
        "    prompt_new = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
        "    sample[\"prompt\"] = prompt_new\n",
        "    return sample\n",
        "\n",
        "reference = \"\"\"<|im_start|>user\\nOh, I just saw the best meme - have you seen it?<|im_end|>\\n<|im_start|>assistant\\n\"\"\"\n",
        "sample = train_dataset[0]\n",
        "new_sample = apply_chat_template(sample, tokenizer)\n",
        "assert new_sample[\"chosen\"] == sample[\"chosen\"]\n",
        "assert new_sample[\"rejected\"] == sample[\"rejected\"]\n",
        "assert new_sample[\"prompt\"] == reference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–î–∞–≤–∞–π—Ç–µ –ø—Ä–∏–º–µ–Ω–∏–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –∫ –Ω–∞—à–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1061/1061 [00:00<00:00, 7725.63 examples/s]\n",
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 218/218 [00:00<00:00, 9260.54 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "partial_template = partial(apply_chat_template, tokenizer=tokenizer)\n",
        "train_dataset = train_dataset.map(partial_template)\n",
        "eval_dataset = eval_dataset.map(partial_template)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–¢–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å LoRA –º–æ–¥–µ–ª—å. –£—á–∏—Ç—å DPO –º–æ–∂–Ω–æ –∏ –±–µ–∑ –Ω–µ–µ, –Ω–æ –∫–∞–∫ –≤—ã –ø–æ–º–Ω–∏—Ç–µ –≤ —Ñ–æ—Ä–º—É–ª–µ DPO —É—á–∞–≤—Å—Ç–≤—É—é—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏ - –º—ã –Ω–µ —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –Ω–∞—à–∞ –º–æ–¥–µ–ª—å –¥–∞–ª–µ–∫–æ —É—Ö–æ–¥–∏–ª–∞ –æ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞.\n",
        "–ï—Å–ª–∏ —É—á–∏—Ç—å –≤—Å–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏, —Ç–æ –Ω–∞–º –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—É—é –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç–∏, –∞ —ç—Ç–æ –µ—â–µ –≥–∏–≥–∞–±–∞–π—Ç—ã –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–º –æ—á–µ–Ω—å –Ω—É–∂–Ω—ã, —Ç.–∫. –∫–∞–∂–¥—ã–π –±–∞—Ç—á –≤ DPO –æ–±—É—á–µ–Ω–∏–∏ –≤ –¥–≤–∞ —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –æ–±—ã—á–Ω—ã—Ö –±–∞—Ç—á–µ–π, —Ç–∞–∫ –∫–∞–∫ –º—ã —Å—á–∏—Ç–∞–µ–º –≤—ã—Ö–æ–¥—ã –∏ –ø–æ chosen –∏ –ø–æ rejected.\n",
        "–ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å —ç—Ç–∏–º –±–æ—Ä–æ—Ç—å—Å—è:\n",
        "1. –ü—Ä–µ–¥–ø–æ—Å—á–∏—Ç–∞—Ç—å –≤—Å–µ –≤—ã—Ö–æ–¥—ã —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –ø–æ–¥–≥—Ä—É–∂–∞—Ç—å —ç—Ç–∏ –≤—ã—Ö–æ–¥—ã —Å –∂–µ—Å—Ç–∫–æ–≥–æ –¥–∏—Å–∫–∞. –≠—Ç–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç —Ö–æ—Ä–æ—à–∏–π, –Ω–æ –≤ —ç—Ç–æ—Ç —Ä–∞–∑ –º—ã –ø–æ—Å—Ç—É–ø–∏–º –∏–Ω—Ç–µ—Ä–µ—Å–Ω–µ–µ.\n",
        "2. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LoRA - —Ç–æ–≥–¥–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—É—é –º–æ–¥–µ–ª—å, –Ω–∞–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å LoRA —Å–ª–æ–∏, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –æ–±—É—á–∞–µ–º. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º—ã –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—É—é –º–æ–¥–µ–ª—å, —Ç.–∫. –æ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –Ω–∞—à–µ–π –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç—É –ª–æ–≥–∏–∫—É –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç DPOTrainer –∏ –≤ —ç—Ç–æ–π –∑–∞–¥–∞—á–µ –º—ã –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–∏–º –ø–æ–¥—Ö–æ–¥–æ–º."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import DPOTrainer, DPOConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=8,\n",
        "    target_modules=\"all-linear\",\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–∏–Ω–≥–∞\n",
        "model.enable_input_require_grads()\n",
        "peft_model = get_peft_model(model, peft_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–ó–∞–ø–æ–ª–Ω–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –†–µ–∫–æ–º–µ–Ω–¥—É—é –ø–æ—Å—Ç–∞–≤–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –±–∞—Ç—á —Å–∞–π–∑ 16 (—Å –ø–æ–º–æ—â—å—é –∞–∫–∫—É–º—É–ª—è—Ü–∏–∏), –æ–±—ã—á–Ω—ã–π –±–∞—Ç—á —Å–∞–π–∑ 4, –æ–¥–Ω—É —ç–ø–æ—Ö—É –æ–±—É—á–µ–Ω–∏—è. –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –¥–∞–≤–∞–π—Ç–µ –ø–æ—Å—Ç–∞–≤–∏–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π lr = 1e-3, –Ω–æ –æ–±—ã—á–Ω–æ –æ–Ω –≤ 10 —Ä–∞–∑ –º–µ–Ω—å—à–µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "training_args = DPOConfig(\n",
        "    output_dir=\"checkpoint\",\n",
        "    bf16=True,\n",
        "    gradient_checkpointing=True,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=1,\n",
        "    gradient_checkpointing_kwargs={'use_reentrant':False},\n",
        "    num_train_epochs=1,\n",
        "    dataset_num_proc=1,\n",
        "    dataloader_num_workers=1,\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    save_total_limit=1,\n",
        "    eval_steps=20,\n",
        "    eval_strategy=\"steps\",\n",
        "    learning_rate=1e-3,\n",
        "    beta=0.1,\n",
        ")\n",
        "trainer = DPOTrainer(\n",
        "    model=peft_model,\n",
        "    ref_model=None,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    processing_class=tokenizer,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "# –ø–æ—è—Å–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏!!!\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    gens = peft_model.generate(**inputs, do_sample=True, temperature=0.8)\n",
        "    print(\"Generated answer\")\n",
        "    print(tokenizer.decode(gens[0, inputs[\"input_ids\"].size(1):].tolist()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "–ö–∞–∫ –≤–∏–¥–∏–º, —É –Ω–∞—Å –ø–æ–ª—É—á–∏–ª–∞—Å—å –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –∞–∫—Ç–∏–≤–Ω–µ–µ —Å—Ç–∞–≤–∏—Ç —Å–º–∞–π–ª–∏–∫–∏. –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º, –∫–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞–º –¥–æ—Å—Ç—É–ø–Ω—ã –≤ —Ä–∞–º–∫–∞—Ö –æ–±—É—á–µ–Ω–∏—è:\n",
        "\n",
        "* loss - dpo —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å\n",
        "* logps/chosen - –ª–æ–≥–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ chosen –æ—Ç–≤–µ—Ç–∞. –ß–µ–º –æ–Ω–∏ –±–ª–∏–∂–µ –∫ 0, —Ç–µ–º –≤–µ—Ä–æ—è—Ç–Ω–µ–µ –º—ã –æ—Ü–µ–Ω–∏–≤–∞–µ–º —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç. –≠—Ç–∞ –º–µ—Ç—Ä–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏ –∏ –ø—Ä–∏–±–ª–∏–∂–∞—Ç—å—Å—è –∫ 0\n",
        "* logps/rejected - –ª–æ–≥–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ rejected –æ—Ç–≤–µ—Ç–∞. –ß–µ–º –æ–Ω–∏ –±–ª–∏–∂–µ –∫ 0, —Ç–µ–º –≤–µ—Ä–æ—è—Ç–Ω–µ–µ –º—ã –æ—Ü–µ–Ω–∏–≤–∞–µ–º —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç. –≠—Ç–∞ –º–µ—Ç—Ä–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–∞–¥–∞—Ç—å –∏ –ø—Ä–∏–±–ª–∏–∂–∞—Ç—å—Å—è –∫ -inf\n",
        "* rewards/chosen - `self.beta * (chosen_logps.to(device) - ref_chosen_logps.to(device))` - –ª–æ–≥–∞—Ä–∏—Ñ–º –æ—Ç–Ω–æ—à–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π chosen –æ—Ç–≤–µ—Ç–∞ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏, –º–µ—Ç—Ä–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏\n",
        "* rewards/rejected - `self.beta * (rejected_logps.to(device) - ref_rejected_logps.to(device))` - –ª–æ–≥–∞—Ä–∏—Ñ–º –æ—Ç–Ω–æ—à–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π chosrejected–µ—Ç–∞ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏, –º–µ—Ç—Ä–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–∞–¥–∞—Ç—å\n",
        "* rewards/margins - —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É logps/chosen –∏ logps/rejected, –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å–∫–æ–ª—å–∫–æ –≤–µ—Ä–æ—è—Ç–Ω–µ–µ –º—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º chosen –æ—Ç–≤–µ—Ç, —á–µ–º rejected\n",
        "* rewards/accuracies - –¥–æ–ª—è —Å—ç–º–ø–ª–æ–≤ –≤ –±–∞—Ç—á–µ, –≥–¥–µ chosen –æ—Ç–≤–µ—Ç—É –º—ã —Å—Ç–∞–≤–∏–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—à–µ, —á–µ–º rejected\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "LoRA –º–æ–∂–Ω–æ –∑–∞–º–µ—Ä–¥–∂–∏—Ç—å –≤ –º–æ–¥–µ–ª—å, –ø–æ—Å–ª–µ —á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç –ø–æ –∂–µ–ª–∞–Ω–∏—é.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model = peft_model.merge_and_unload()\n",
        "model.save_pretrained(\"model_ckpt\")\n",
        "tokenizer.save_pretrained(\"model_ckpt\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
