{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ad1173",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5ad1173",
    "outputId": "4d8f6051-eda8-474a-a8d5-a7d06512b1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d663f600",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459,
     "referenced_widgets": [
      "9304f07a754747608b94a94782cac7cc",
      "c2f14985d19446708cdccfdb3840e7cc",
      "9fc58d97c2ef4a8d97ff244da41a2af9",
      "39f69d24716b459abd1a4549ddb9a610",
      "420a2e840bf24252a8812b16914aa6ec",
      "6573e3da701544639b0d7dbd3f88d3ad",
      "bc81089726b74514b543a3d571126c58",
      "2e002b93655842f0b11f59c5d028796c",
      "4fe7f5b3c48541ac8af0ac29eacc51ac",
      "2893b20e7de647bda7830decaac73709",
      "d12ec05d02e8481bb2c719e5f2e813d3",
      "27926da0475443b7b1c85bccd5664db0",
      "befec435a2fe4e0f9dc1207f723c411a",
      "805cbf11c9ca438487da37b0a3e819ee",
      "0042f04d3b2d494d825820840c63a218",
      "924a98576dc24025b02bb27c3f428a20",
      "7c5a22fa943548b89735a5005374fb64",
      "dbe50e6947f04a9baea2e0d6b88f9ef7",
      "6092bcf6f35a407e870b56d87fc862b4",
      "1560a393b2bf4205897c8d2930964c31",
      "47ec18476ab04bcaae79c83db08b30d7",
      "ccf143abffb74477905aed0f5758951f",
      "2b6c5394f71149e28ba700d0f1c8926e",
      "47bb6250c92e4138be80aed57ee97053",
      "6b12a650addb489abc85002e49621203",
      "f224c525afc949a6936c339d669be1c0",
      "1b6420efada54c80bf09d6a45fc781e5",
      "80493ebab92646f38eb6f1f97dce2b57",
      "d49c799a7dfd414db2e6dc162dca34d6",
      "69467dcaf6414f7ba30b232828fa84ae",
      "1715b0af5c994f8989f636a8581d67a3",
      "24f2d38a6f7c4298b037eb8c43b12df3",
      "a2715701a4484e93aec04a7a5d653dbd",
      "fc726b7ae72d4b15994a7052299b452c",
      "5a174f53fee443d88f47a09a9f84c746",
      "139dd6e93d064808a3becdad8fe330e0",
      "8538f7ddd7544576b5f9d5768a5f5a25",
      "6a4ee693b33f49e2809b42aba198894c",
      "50bf10a82c4b484f882f1ec199a657a1",
      "f676d51df9fe422fbd47d323fde16e5c",
      "8f5b0082a40b47d3b6d310f371555071",
      "53ba61a102514c158bbb1c257b74362a",
      "4cbf8fc1f86b4ce3a8fd9a221f941466",
      "73cd83bc17c948108a31d9960aac5cde",
      "efe247cd494e411db56b3d084140eedc",
      "6bdf3456ad8842bbbcc2fde169663224",
      "57ffd579807043119696059cf26d2833",
      "138aad9f4f1a46419ad0eafe48f79e9e",
      "90dad4abc4b445938d83a1b002ffba74",
      "af6484a8307e47f9841f88fecb633d4e",
      "0fdb698d2ab64b50b7b7bb1361613cee",
      "2aade552cfb94f50ae72c16d1bc250fe",
      "e8b8789d978c4a99b85db921bdfba03c",
      "ef03df5b6931497198e3ded3eddadd9c",
      "5d85bb2e57d64a25af8aa1feff141106",
      "3b4c92a27e8046a0900d8e0068e4170c",
      "f8f4230a34294eeea443acafdfa59cce",
      "0c4db23a6381432280780b9937b2341a",
      "d43a013b4c284efb870badf919ca251c",
      "322c07a2ea50443d93b9be2ff680c078",
      "5d52d41b06d34bc18207b113d5113117",
      "144d0b1a0a3a413999b37bf6e1c5ebc2",
      "8f8c2986e92f4b0c92ad6177b6a1d772",
      "c593bd1741a643af9b976c0342fcbf2c",
      "84be30df6615409c93fa49fb8804f07f",
      "f2c432aad70f4b829a6d71f00a33729d",
      "3bb9e8c7f4c242e3926cfad4c6b1eba0",
      "cb2a265bf9ce46699fe79aa6c8914789",
      "62aae5b3b5c442b5b5bacdc57a74fe02",
      "5824ebca0c9d427db6d762b9c84a528a",
      "0af77ef7255044f281689bf4e9920f52",
      "c2d35eb971794ee6806d936bbb5a35f3",
      "a41ad52f4f864f7bbd62915d72d5fc36",
      "69f4758d39e240dd92e47da74dffb9dc",
      "4f9255668f9848b19f11db9c49b068c2",
      "1601ceee55b641f68e033b90cf4988d2",
      "31a5fd193b9641229f783381f24591cd",
      "9a76b12ad07642468ddd6be7569a227d",
      "7f1f3742754143d3900f64337d664549",
      "3c2559d553c44382afd15d164cf4fa73",
      "152e3682b9d2441c826b29990f5b2971",
      "5c80b5ea4fea4c699647330a7dbe604a",
      "2dbd7d6ccba34397bf58105dbc312c67",
      "abb02237fd344b3c9dcbb2ccee9fe2fb",
      "c5d51a6e3aa643358ba4af324f676280",
      "83253d555da04b199d36c95ad2b0efa8",
      "7368844d2a1144e388c45d335dd0eca6",
      "d837ff85dc1142b2ad6c4aff8319a2c6",
      "ec48462fc5c541bd8d38490a918d4a33",
      "8b57098825b14807b8302bdae37c5e77",
      "7057be52e08f4ff4a314372676c1089e",
      "fd4bdc7c2d6b4872b00140929e311415",
      "d7563830a1ff4abd8bc3c0305c12efb2",
      "1f152861c7974643a5fa4f20a7421c90",
      "e43907de99e0411f8586b7e3fee2695e",
      "0bdfd26f0efb4065a8247d069dabb4d4",
      "61f89044a34a4b31836ad6170c0150ca",
      "8c298c7f037b408bab7e4c0632fa8c50",
      "aa7b4cdab70d46eb8620b4cfb017bc02",
      "4f526d697e7e4454a5283a2f7938e831",
      "3214ca12bb9c4549a9c41f6040d5908c",
      "302c35e2497e4bcca54f5233e46c2af1",
      "c4b19cffce4941f895a57181dc1ad1aa",
      "4f048a3e1d534a7ab8c37b7276ffe31b",
      "dacb7596aca947f0b25b3c6c4bbb18d5",
      "869abcb0dd2b4b3982c253481f4f2964",
      "239bfaebff9f4ddfb2075b2f398b260e",
      "ca46976dbead4772908263de47caab4e",
      "14408ae289f74529811ac7ae09ed13ec",
      "828c7b590e4d42629d4d2a88eeb0b473"
     ]
    },
    "id": "d663f600",
    "outputId": "421481a9-1dbf-4a15-8ed8-1fe67fb1fd59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9304f07a754747608b94a94782cac7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27926da0475443b7b1c85bccd5664db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6c5394f71149e28ba700d0f1c8926e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc726b7ae72d4b15994a7052299b452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe247cd494e411db56b3d084140eedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4c92a27e8046a0900d8e0068e4170c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb9e8c7f4c242e3926cfad4c6b1eba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a76b12ad07642468ddd6be7569a227d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec48462fc5c541bd8d38490a918d4a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f526d697e7e4454a5283a2f7938e831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "if False:\n",
    "    name_big = \"unsloth/Llama-3.2-3B\"\n",
    "    name_small = \"unsloth/Llama-3.2-1B\"\n",
    "else:\n",
    "    name_big = \"openai-community/gpt2-medium\"\n",
    "    name_small = \"openai-community/gpt2\"\n",
    "\n",
    "model_big = AutoModelForCausalLM.from_pretrained(name_big).to(device)\n",
    "model_small = AutoModelForCausalLM.from_pretrained(name_small).to(device)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(name_big, pad_token_id=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ff647",
   "metadata": {
    "id": "1d1ff647"
   },
   "source": [
    "# Distillation\n",
    "В данном задании мы познакомимся с лоссами в дистилляции. *Так как обучения в данном задании нет, то для экономии памяти подсчет функции потерь обернут в torch.no_grad(), при обучении в реальных сценариях этот декоратор нужно обязательно убрать*\n",
    "\n",
    "## Hard-Label Distillation - 10 баллов\n",
    "Hard-Label дистилляция заключается в том, что мы учимся на метках модели учителя, то есть:\n",
    "1. Модель учитель размечает какой-то датасет, в нашем случае генерирует продолжения текстов из какого-либо корпуса.\n",
    "2. Считается обычный CrossEntropyLoss модели студента на сгенерированных текстах в задаче языкового моделирования. **Считать функцию потерь нужно только по сгенерированному тексту, а не по префиксу, по которому функция потерь считалась, т.е. префикс должен быть замаскирован**\n",
    "\n",
    "Идейно это обучение можно описать так:\n",
    "мы сгенерировали данных моделью-учителем и просто дообучили на этом модель-ученика.\n",
    "\n",
    "## Soft-Label Distillation - 10 баллов\n",
    "В этом варианте мы учимся на распределении, которое нам выдает модель-учитель. В soft-label дистилляции мы стремимся не только повторить метки учителя, но и его распределение. Например, если модель учителя выдавала вероятности \\[0.7, 0.2, 0.1\\], то в Hard-Label дистилляции ученик будет восстанавливать распределение \\[1, 0, 0\\], а в soft-label \\[0.7, 0.2, 0.1\\]. В этом нам поможет KL дивергенция.\n",
    "\n",
    "\n",
    "1. Считаем распределение logits/probs модели-учителя на тексте.\n",
    "2. Считаем KLDivLoss между выходами модели-ученика на тексте и выходами модели учителя.\n",
    "\n",
    "В данном виде обучения мы используем не только токены, которые сгенерировала модель учитель, но и ее распределения вероятностей по словарю. Подобная техника дистилляции может помочь модели-ученику лучше моделировать вероятность модели-учителя.\n",
    "\n",
    "\n",
    "\n",
    "# Математический вопрос на 5 баллов\n",
    "> Как связана KL-дивергенция и кроссэнтропия?\n",
    "\n",
    "KLDiv(P||Q) = crossentropy(P, Q) - entropy(P)\n",
    "То есть минимизация кроссэнтропии ведет к минимизации KLDiv, так как энтропия не зависит от распределения Q.\n",
    ">  В soft-label есть ли разница, кого считать в soft-label distillation?\n",
    "На первый взгляд, если будем считать только кроссэнтропию, то решение сведется к hard label. В soft label же мы хотим приближать не просто argmax, а распределения.\n",
    "С другой стороны, если напишем кроссэнтропию между непрерывными распределениями сами, вместо использования готового лоса в торче, то по идее градиенты будут теми же, что и при подсчете KL, так как entropy(P) константа.\n",
    "Еще с другой стороны лосс считается на батче и, возможно, на маленьких батчах entropy(P) работает как регуляризация.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22504194",
   "metadata": {
    "id": "22504194"
   },
   "outputs": [],
   "source": [
    "prefix = \"Мама мыла раму\"\n",
    "@torch.no_grad()\n",
    "def hard_label_distillation_loss(model_teacher, model_student, prefix):\n",
    "    inputs = tokenizer(prefix, return_tensors=\"pt\")\n",
    "    inputs[\"input_ids\"] = inputs[\"input_ids\"].to(device)\n",
    "    inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(device)\n",
    "    outputs = model_teacher.generate(**inputs, do_sample=False, max_new_tokens=5, use_cache=True)\n",
    "    # outputs - выходы учителя (с префиксом!). Нужно посчитать по ним обычный LM loss (кроссэнтропию)\n",
    "    # ученика.\n",
    "    prefix_len = inputs[\"input_ids\"].shape[1]\n",
    "\n",
    "    logits = model_student(outputs[:, :-1]).logits\n",
    "    logits_to_compare = logits[:, -5:, :]\n",
    "\n",
    "    # берем токены учителя без префикса для подсчета лоса\n",
    "    student_targets = outputs[:, prefix_len:]\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits_to_compare.view(-1, logits_to_compare.size(-1)),  # [5, vocab]\n",
    "        student_targets.view(-1)                                 # [5]\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def soft_label_distillation_loss(model_teacher, model_student, text):\n",
    "    loss_fn = torch.nn.KLDivLoss()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs[\"input_ids\"] = inputs[\"input_ids\"].to(device)\n",
    "    inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(device)\n",
    "    teacher_logits = model_teacher(**inputs).logits\n",
    "    # teacher_logits - выходы учителя. Нужно посчитать с ними KLDivLoss, внимательно\n",
    "    # посмотрите на документацию https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html\n",
    "\n",
    "    student_logits = model_student(**inputs).logits\n",
    "    loss = loss_fn(\n",
    "        input=student_logits.log_softmax(-1),\n",
    "        target=teacher_logits.softmax(-1),\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a8681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]),)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gradient(torch.tensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4e8af5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba4e8af5",
    "outputId": "3f6c0ed0-91e4-4909-96bb-ea3a7babd97f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_big' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(hard_label_distillation_loss(\u001b[43mmodel_big\u001b[49m, model_small, prefix)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.3893\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(soft_label_distillation_loss(model_big, model_small, prefix)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m7.0790e-06\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-3\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТесты прошли успешно\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_big' is not defined"
     ]
    }
   ],
   "source": [
    "assert abs(hard_label_distillation_loss(model_big, model_small, prefix).item() - 1.3893) < 1e-3\n",
    "assert abs(soft_label_distillation_loss(model_big, model_small, prefix).item() - 7.0790e-06) < 1e-3\n",
    "print(\"Тесты прошли успешно\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c8b614",
   "metadata": {
    "id": "13c8b614"
   },
   "source": [
    "# Speculative Decoding - 15 баллов\n",
    "В этом задании необходимо написать спекулятивное декодирование на pytorch. **Генерации необходимо делать жадно.**\n",
    "\n",
    "1. Генерируете n токенов маленькой моделью\n",
    "2. Проверяете, выберет ли эти токены большая модель при жадной генерации (должен быть вызван один forward большой модели, вызывать big_model.generate на этом этапе нельзя)\n",
    "3. Если все токены выбраны большой моделью, принимаете их и возвращаетесь на шаг 1\n",
    "4. Если какой-то токен выбран ошибочно, подаете вместо него правильный токен с шага 2 и возвращаетесь на шаг 1.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "LhGFRPvjvHL7",
   "metadata": {
    "id": "LhGFRPvjvHL7"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def speculative_generate(big_model, small_model, prefix, max_num_tokens, n):\n",
    "\n",
    "    input_ids = tokenizer(prefix, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    start_size = input_ids.size(1)\n",
    "    while input_ids.size(1) - start_size < max_num_tokens:\n",
    "        # Генерируем маленькой моделью последовательность small_generation\n",
    "        # генерируем n токенов жадно\n",
    "        small_generation = small_model.generate(\n",
    "            input_ids=input_ids, max_new_tokens=n, do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        num_generated_tokens = small_generation.size(1) - input_ids.size(1)\n",
    "\n",
    "        # Проверяем последовательность small_generation, считаем по ней logits\n",
    "        # большой модели\n",
    "        big_model_logits = big_model(small_generation).logits\n",
    "        big_model_generations = big_model_logits[:, -num_generated_tokens - 1:].argmax(dim=2)\n",
    "\n",
    "        # для ясности\n",
    "        last_big_token = big_model_generations[:, -1:]\n",
    "        big_model_generations = big_model_generations[:, :-1]\n",
    "\n",
    "        mismatch = False\n",
    "        for i in range(num_generated_tokens):\n",
    "            # нашли расхождение\n",
    "            if big_model_generations[0, i] != small_generation[0, input_ids.size(1) + i]:\n",
    "                mismatch = True\n",
    "                # Если оно сразу, то берем первый предсказанный большой моделью токен\n",
    "                if i == 0:\n",
    "                    input_ids = torch.concat(\n",
    "                        tensors=[input_ids, big_model_generations[:, 0:1]],\n",
    "                        dim=1\n",
    "                      )\n",
    "                # иначе берем часть токенов, предсказанных маленькой моделью + правильный токен от большой модели\n",
    "                else:\n",
    "                    correct_small_tokens = small_generation[:, input_ids.size(1):input_ids.size(1) + i]\n",
    "                    correct_big_token = big_model_generations[:, i: i+1]\n",
    "\n",
    "                    input_ids = torch.concat(\n",
    "                          tensors=[input_ids, correct_small_tokens, correct_big_token],\n",
    "                          dim=1\n",
    "                        )\n",
    "                break\n",
    "                print(f\"Accepted {i}/{n} tokens\")\n",
    "            else:\n",
    "                print(f\"Accepted {n}/{n} tokens\")\n",
    "\n",
    "\n",
    "        if not mismatch:\n",
    "            # если расхождений не было, принимаем всю последовательность + последний токен от большой модели\n",
    "            input_ids = torch.concat(\n",
    "                tensors=[input_ids, small_generation[:, -num_generated_tokens:], last_big_token],\n",
    "                dim=1\n",
    "            )\n",
    "    return tokenizer.decode(input_ids[0, start_size:start_size + max_num_tokens].cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a863af34",
   "metadata": {
    "id": "a863af34"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "# SYSTEM PREAMBLE\n",
    "1) You are an excellent Python software developer with over 10 years of experience. You have a strong understanding of Python related topics, data structures, libraries, frameworks, algorithms, best practices and optimization techniques.\n",
    "2) You are here to help the user (the software developer) by breaking his request in ## TASK into logical steps and writing high-quality and efficient code to implement each step.\n",
    "3) You have to return the entire code.\n",
    "4) Follow \"Answering rules\" without exception.\n",
    "\n",
    "## ANSWERING RULES\n",
    "1) Repeat the question before answering it.\n",
    "2) Always follow \"CHAIN OF THOUGHTS\" to execute the task.\n",
    "\n",
    "## CHAIN OF THOUGHTS\n",
    "1) **OBEY the EXECUTION MODE**\n",
    "2) **TASK ANALYSIS:**\n",
    "   - Understand the user's request thoroughly.\n",
    "   - Identify the key components and requirements of the task.\n",
    "3) **PLANNING: CODDING:**\n",
    "   - Break down the task into logical, sequential steps.\n",
    "   - Outline the strategy for implementing each step.\n",
    "4) **CODING:**\n",
    "   - Explain your thought process before writing any code.\n",
    "   - Write the entire code for each step, ensuring it is clean, optimized, and well-commented.\n",
    "   - Handle edge cases and errors appropriately.\n",
    "5) **VERIFICATION:**\n",
    "   - Review the complete code solution for accuracy and efficiency.\n",
    "   - Ensure the code meets all requirements and is free of errors.\n",
    "\n",
    "## TASK\n",
    "\n",
    "Write a python function that receives the following JSON as input and enters data from it into the Google Sheet.\n",
    "\n",
    "{\n",
    "    'date': '31-05-2024',\n",
    "    'revenue': 90000,\n",
    "    'person' : 'User1',\n",
    "    'expensesList': [30000, 14000, 10000, 2000, 15000],\n",
    "    'expensesDescList': [ 'Ключи', 'Ключи2', 'Счет за такси', 'Клей, пластины', 'Провод 40м'],\n",
    "    'expensesTypeList': ['Закупки', 'Закупки', 'Расходы', 'Ремонт', 'Ремонт']\n",
    "}\n",
    "\n",
    "There is a date in JSON, you can use it to determine the month.\n",
    "The data is entered into a list with the name of the month. If such a list does not exist yet, then you need to create a list with a new month inside the sheet.\n",
    "\n",
    "The list should have the following columns (the first rows are used as headings):\n",
    "A1: Дата расхода,\n",
    "B1: сумма расхода,\n",
    "C1: описание расхода,\n",
    "D1: тип расхода,\n",
    "E1: кто внес данные\n",
    "\n",
    "G1: Дата выручки\n",
    "H1: Сумма выручки\n",
    "I1: Кто внес данные\n",
    "\n",
    "Please separate expenses and profits with a blank column.\n",
    "Please sort expenses by date, including those already listed in Google sheet list.\n",
    "Please sort earnings by date, including those already listed in Google sheet list.\n",
    "\n",
    "It is prohibited to use oauth2client as it is deprecated.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90be9a91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90be9a91",
    "outputId": "7ca273e3-c9b6-48d2-ae48-641c0c43cb84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## ANSWERING RULES\n",
      "1) Do not use oauth2client.\n",
      "\n",
      "2) Do not use oauth2client as it is deprecated.\n",
      "\n",
      "3) Do not use oauth2client as it is deprecated.\n",
      "\n",
      "4) Do not use oauth2client as it is deprecated.\n",
      "\n",
      "5) Do not use oauth2client as it is deprecated.\n",
      "\n",
      "## VERIFICATION\n",
      "\n",
      "1) Review the complete code solution for accuracy and efficiency.\n",
      "\n",
      "2) Ensure the code meets all requirements and is free of errors.\n",
      "\n",
      "## TASK\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "res_big = tokenizer.batch_decode(model_big.generate(**model_inputs, do_sample=False, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)[:, model_inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "print(res_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcf06765",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcf06765",
    "outputId": "f08d172f-c065-4395-ea85-56eb191947ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n",
      "Accepted 5/5 tokens\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "res_spec = speculative_generate(big_model=model_big, small_model=model_small, prefix=prompt, max_num_tokens=128, n=5)\n",
    "assert res_spec == res_big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f231551b",
   "metadata": {
    "id": "f231551b"
   },
   "source": [
    "## HF speculative decoding - 5 баллов\n",
    "Теперь попробуйте использовать функцию спекулятивного декодирования из [transformers](https://huggingface.co/docs/transformers/main/en/generation_strategies#speculative-decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2809fd2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2809fd2e",
    "outputId": "6a806da0-d0c8-45ed-cb91-1e89d019fc40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for big model inference 2.4584481716156006\n",
      "Elapsed time for speculative 0.6233077049255371\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "outputs = model_big.generate(**inputs, do_sample=False, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "print(f\"Elapsed time for big model inference {time.time() - start}\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "outputs = model_big.generate(**inputs, assistant_model=model_small, pad_token_id=tokenizer.eos_token_id)\n",
    "# print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "print(f\"Elapsed time for speculative {time.time() - start}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a27e29",
   "metadata": {
    "id": "37a27e29"
   },
   "outputs": [],
   "source": [
    "del model_big, model_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c192f4",
   "metadata": {
    "id": "f7c192f4"
   },
   "source": [
    "# Бонусная часть - 20 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da576fb",
   "metadata": {
    "id": "2da576fb"
   },
   "source": [
    "# Inference Speedup\n",
    "\n",
    "## Seminar\n",
    "\n",
    "\n",
    "### План\n",
    "\n",
    "- Сделать введение в triton GeMM\n",
    "- Показать времена запуска кернелов GeMV, GeMM и их скейлинг по батчу\n",
    "- Подчеркнуть про время на запуск DecodeMany vs Decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1cdef",
   "metadata": {
    "id": "f8d1cdef"
   },
   "outputs": [],
   "source": [
    "! pip install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42930b3e",
   "metadata": {
    "id": "42930b3e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"triton version:\", triton.__version__)\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde72929",
   "metadata": {
    "id": "cde72929"
   },
   "source": [
    "### Catch activation and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7c9b9",
   "metadata": {
    "id": "31d7c9b9"
   },
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "# challenging input\n",
    "prompt = \"\"\"\n",
    "# SYSTEM PREAMBLE\n",
    "1) You are an excellent Python software developer with over 10 years of experience. You have a strong understanding of Python related topics, data structures, libraries, frameworks, algorithms, best practices and optimization techniques.\n",
    "2) You are here to help the user (the software developer) by breaking his request in ## TASK into logical steps and writing high-quality and efficient code to implement each step.\n",
    "3) You have to return the entire code.\n",
    "4) Follow \"Answering rules\" without exception.\n",
    "\n",
    "## ANSWERING RULES\n",
    "1) Repeat the question before answering it.\n",
    "2) Always follow \"CHAIN OF THOUGHTS\" to execute the task.\n",
    "\n",
    "## CHAIN OF THOUGHTS\n",
    "1) **OBEY the EXECUTION MODE**\n",
    "2) **TASK ANALYSIS:**\n",
    "   - Understand the user's request thoroughly.\n",
    "   - Identify the key components and requirements of the task.\n",
    "3) **PLANNING: CODDING:**\n",
    "   - Break down the task into logical, sequential steps.\n",
    "   - Outline the strategy for implementing each step.\n",
    "4) **CODING:**\n",
    "   - Explain your thought process before writing any code.\n",
    "   - Write the entire code for each step, ensuring it is clean, optimized, and well-commented.\n",
    "   - Handle edge cases and errors appropriately.\n",
    "5) **VERIFICATION:**\n",
    "   - Review the complete code solution for accuracy and efficiency.\n",
    "   - Ensure the code meets all requirements and is free of errors.\n",
    "\n",
    "## TASK\n",
    "\n",
    "Write a python function that receives the following JSON as input and enters data from it into the Google Sheet.\n",
    "\n",
    "{\n",
    "    'date': '31-05-2024',\n",
    "    'revenue': 90000,\n",
    "    'person' : 'User1',\n",
    "    'expensesList': [30000, 14000, 10000, 2000, 15000],\n",
    "    'expensesDescList': [ 'Ключи', 'Ключи2', 'Счет за такси', 'Клей, пластины', 'Провод 40м'],\n",
    "    'expensesTypeList': ['Закупки', 'Закупки', 'Расходы', 'Ремонт', 'Ремонт']\n",
    "}\n",
    "\n",
    "There is a date in JSON, you can use it to determine the month.\n",
    "The data is entered into a list with the name of the month. If such a list does not exist yet, then you need to create a list with a new month inside the sheet.\n",
    "\n",
    "The list should have the following columns (the first rows are used as headings):\n",
    "A1: Дата расхода,\n",
    "B1: сумма расхода,\n",
    "C1: описание расхода,\n",
    "D1: тип расхода,\n",
    "E1: кто внес данные\n",
    "\n",
    "G1: Дата выручки\n",
    "H1: Сумма выручки\n",
    "I1: Кто внес данные\n",
    "\n",
    "Please separate expenses and profits with a blank column.\n",
    "Please sort expenses by date, including those already listed in Google sheet list.\n",
    "Please sort earnings by date, including those already listed in Google sheet list.\n",
    "\n",
    "It is prohibited to use oauth2client as it is deprecated.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "generation_output = model.generate(**model_inputs, streamer=streamer, max_new_tokens=1024)\n",
    "\n",
    "class Catcher(nn.Module):\n",
    "    def __init__(self, inps: List, module: nn.Module):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.inps = inps\n",
    "\n",
    "    def forward(self, inp, **kwargs):\n",
    "        self.inps.append(inp.to(\"cpu\"))\n",
    "        raise ValueError\n",
    "\n",
    "layer = model.model.layers[0]\n",
    "inps = []\n",
    "layer.self_attn.q_proj = Catcher(inps, layer.self_attn.q_proj) # wrap\n",
    "\n",
    "try:\n",
    "    model(model_inputs.input_ids)\n",
    "except ValueError as e:\n",
    "    layer.self_attn.q_proj = layer.self_attn.q_proj.module\n",
    "\n",
    "print(inps[0].shape)\n",
    "\n",
    "weight = layer.self_attn.q_proj.weight # unwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba024f",
   "metadata": {
    "id": "78ba024f"
   },
   "source": [
    "#### When to Use Triton\n",
    "- Optimization Steps:\n",
    "1. Use torch.compile():\n",
    "    - Start by using torch.compile() to optimize your code.\n",
    "2. Adapt Your Code:\n",
    "    - Rewrite code to be more suitable for torch.compile().\n",
    "        - E.g., eliminate graph breaks to enable CUDA graphs.\n",
    "3. Profile and Identify Bottlenecks:\n",
    "    - Find slow parts of your code using profiling tools.\n",
    "    - Write custom Triton kernels for these parts.\n",
    "4. Consider CUDA:\n",
    "    - If still not fast enough, write custom CUDA kernels.\n",
    "\n",
    "**Note**: For maximum performance from the start, you may choose CUDA directly.\n",
    "\n",
    "#### Rough Edges in Triton\n",
    "- New-ish Project:\n",
    "    - Contains rough edges; code may not behave as expected.\n",
    "    - Expected to become more polished over time.\n",
    "- Recommendation:\n",
    "    - Debugging is important; use “simulator mode” when possible.\n",
    "    - Be aware of limitations on older GPUs or with certain operations.\n",
    "    \n",
    "    Resources (самое полезное):\n",
    "- [GPU MODE Lecture 14: Practitioners Guide to Triton](https://christianjmills.com/posts/cuda-mode-notes/lecture-014/#auto-tuning) – тут есть базовое описание про разработку на Triton, его +/-, практические примеры с полным пояснением и про оптимизацию\n",
    "- [Flash-Decoding for long-context inference](https://pytorch.org/blog/flash-decoding/) – описание SPLIT_K оптимизации для более быстрого инференса на степе decoding-a засчет лучше утилизации GPU\n",
    "\n",
    "Менее полезное, но интересное:\n",
    "- [Deep Dive on the Hopper TMA Unit for FP8 GEMMs](https://pytorch.org/blog/hopper-tma-unit/) – про важность TMA unit для Hopper и BlackWell.\n",
    "- [Persistent Matmul](https://triton-lang.org/main/getting-started/tutorials/09-persistent-matmul.html) – специальная версия GeMM под Hopper и BlackWell с поддержкой TMA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d93b55",
   "metadata": {
    "id": "a0d93b55"
   },
   "outputs": [],
   "source": [
    "def is_cuda():\n",
    "    return triton.runtime.driver.active.get_current_target().backend == \"cuda\"\n",
    "\n",
    "assert is_cuda(), \"CUDA only tutorial\"\n",
    "ref_lib = 'cuBLAS'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0561b",
   "metadata": {
    "id": "f3e0561b"
   },
   "outputs": [],
   "source": [
    "def get_cuda_autotune_config():\n",
    "    return [\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64,  'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64,  'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64,  'BLOCK_SIZE_N': 32,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 32,  'BLOCK_SIZE_N': 64,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32,  'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64,  'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32,  'GROUP_SIZE_M': 16}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64,  'GROUP_SIZE_M': 16}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64,  'GROUP_SIZE_M': 16}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 16}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 1, 'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64,  'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64,  'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64,  'BLOCK_SIZE_N': 32,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 32,  'BLOCK_SIZE_N': 64,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32,  'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64,  'GROUP_SIZE_M': 8}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32,  'GROUP_SIZE_M': 16}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64,  'GROUP_SIZE_M': 16}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64,  'GROUP_SIZE_M': 16}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 16}, num_stages=3, num_warps=8),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "        # custom\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 16,  'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 16,  'BLOCK_SIZE_N': 64,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'SPLIT_K': 2, 'BLOCK_SIZE_M': 16, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 4, 'BLOCK_SIZE_M': 16, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 4, 'BLOCK_SIZE_M': 16,  'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 4, 'BLOCK_SIZE_M': 16,  'BLOCK_SIZE_N': 64,  'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5, num_warps=2),\n",
    "        triton.Config({'SPLIT_K': 4, 'BLOCK_SIZE_M': 16, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "        triton.Config({'SPLIT_K': 4, 'BLOCK_SIZE_M': 16, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 256, 'GROUP_SIZE_M': 16}, num_stages=2, num_warps=4),\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_autotune_config():\n",
    "    if is_cuda():\n",
    "        return get_cuda_autotune_config()\n",
    "    raise NotImplementedError(\"ooops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585dcd15",
   "metadata": {
    "id": "585dcd15"
   },
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    "    reset_to_zero=['c_ptr']\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "    # Pointers to matrices\n",
    "    a_ptr, b_ptr, c_ptr,\n",
    "    # Matrix dimensions\n",
    "    M, N, K,\n",
    "    # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "    # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`\n",
    "    # by to get the element one row down (A has M rows).\n",
    "    stride_am, stride_ak,\n",
    "    stride_bk, stride_bn,\n",
    "    stride_cm, stride_cn,\n",
    "    # Meta-parameters\n",
    "    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "    GROUP_SIZE_M: tl.constexpr, SPLIT_K: tl.constexpr,\n",
    "):\n",
    "    \"\"\"Kernel for computing the matmul C = A x B.\n",
    "    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n",
    "    \"\"\"\n",
    "    # -----------------------------------------------------------\n",
    "    # Map program ids `pid` to the block of C it should compute.\n",
    "    # This is done in a grouped ordering to promote L2 data reuse.\n",
    "    # See above `L2 Cache Optimizations` section for details.\n",
    "    pid = tl.program_id(axis=0)\n",
    "    pid_sp_k = tl.program_id(axis=1)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + (pid % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Create pointers for the first blocks of A and B.\n",
    "    # We will advance this pointer as we move in the K direction\n",
    "    # and accumulate\n",
    "    # `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\n",
    "    # `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers\n",
    "    # See above `Pointer Arithmetics` section for details\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    offs_k = pid_sp_k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K * SPLIT_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K * SPLIT_K, other=0.0)\n",
    "        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K * SPLIT_K, other=0.0)\n",
    "        # We accumulate along the K dimension.\n",
    "        accumulator += tl.dot(a, b, allow_tf32=False)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * SPLIT_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * SPLIT_K * stride_bk\n",
    "    # You can fuse arbitrary activation functions here\n",
    "    # while the accumulator is still in FP32!\n",
    "    c = accumulator.to(c_ptr.dtype.element_ty)\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    if SPLIT_K == 1:\n",
    "        tl.store(c_ptrs, c, mask=c_mask)\n",
    "    else:\n",
    "        tl.atomic_add(c_ptrs, c, mask=c_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6844f",
   "metadata": {
    "id": "01b6844f"
   },
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    # Allocates output.\n",
    "    c = torch.zeros((M, N), device=a.device, dtype=torch.float16)\n",
    "    grid = lambda META: (\n",
    "        triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\n",
    "        META['SPLIT_K'],\n",
    "    )\n",
    "    matmul_kernel[grid](\n",
    "        a, b, c,\n",
    "        M, N, K,\n",
    "        a.stride(0), a.stride(1),\n",
    "        b.stride(0), b.stride(1),\n",
    "        c.stride(0), c.stride(1),\n",
    "    )\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b41ea",
   "metadata": {
    "id": "605b41ea"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "a = inps[0][0].to(torch.float16).cuda()\n",
    "b = weight.to(torch.float16).cuda()\n",
    "\n",
    "triton_output = matmul(a, b)\n",
    "torch_output = torch.matmul(a, b)\n",
    "\n",
    "if torch.allclose(triton_output, torch_output, atol=2e-2):\n",
    "    print(\"✅ Triton and Torch match\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ\")\n",
    "    print(f\"triton_output_with_fp16_inputs={triton_output}\")\n",
    "    print(f\"torch_output_with_fp16_inputs={torch_output}\")\n",
    "    assert False, \"Check quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01be72",
   "metadata": {
    "id": "1f01be72"
   },
   "outputs": [],
   "source": [
    "seqlen = inps[0].shape[1]\n",
    "hidden_size = inps[0].shape[2]\n",
    "seqlen, hidden_size\n",
    "\n",
    "\n",
    "def prepare_a(M: int):\n",
    "    inp = inps[0][0]\n",
    "    if M > seqlen:\n",
    "        n_repeats = M // seqlen + 1\n",
    "        return inp.repeat(n_repeats, 1)[:M]\n",
    "    else:\n",
    "        return inp[:M]\n",
    "\n",
    "\n",
    "def benchmark(M, provider, provider_funcs):\n",
    "    N = weight.shape[0]\n",
    "    K = weight.shape[1]\n",
    "\n",
    "    a = prepare_a(M).to(torch.float16).cuda()\n",
    "    b = weight.T.to(torch.float16)\n",
    "    assert a.shape == (M, K), f\"{a.shape} != {(M, K)}\"\n",
    "    assert b.shape == (K, N), b.shape\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    ms, min_ms, max_ms = triton.testing.do_bench(lambda: provider_funcs[provider](a, b), quantiles=quantiles)\n",
    "    perf = lambda ms: ms # TFlops = 2 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23e990",
   "metadata": {
    "id": "5d23e990"
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[2 ** i for i in range(7)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[ref_lib.lower(), \"triton\"],  # Label name for the lines\n",
    "        line_names=[ref_lib, \"Triton\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"ms\",  # Label name for the y-axis\n",
    "        plot_name=\"GeMV-performance-\" + (\"fp16\"),  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"provider_funcs\": {\"triton\": matmul, \"cublas\": torch.matmul}},\n",
    "    ),\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[1024 * i for i in range(4, 21)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[ref_lib.lower(), \"triton\"],  # Label name for the lines\n",
    "        line_names=[ref_lib, \"Triton\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"ms\",  # Label name for the y-axis\n",
    "        plot_name=\"GeMM-performance-\" + (\"fp16\"),  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"provider_funcs\": {\"triton\": matmul, \"cublas\": torch.matmul}},\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "triton.testing.perf_report(configs)(benchmark).run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7e6dc",
   "metadata": {
    "id": "61c7e6dc"
   },
   "source": [
    "## HW\n",
    "\n",
    "### Dynamic W8A8 GeMM\n",
    "\n",
    "> **Важный дисклеймер:** пожалуйста, выполняйте ДЗ к google colab на среде T4, потому что на ней эта домашка оттестирована и уже установлены правильные зависимости по умолчанию, это сэкономит вам кучу времени.\n",
    "\n",
    "Для непослушных: на другом типе видеокарт (H100) код придется сильно переписывать, чтобы учесть архитектурные особенности для максимальной производительности (см. \"менее полезное, но интересное\" выше в семинаре).\n",
    "\n",
    "> **Важный дисклеймер 2:** для выполнения ДЗ нужно запустить код семинара выше, в нем есть нужные helper функции.\n",
    "\n",
    "Useful resources:\n",
    "- [Matrix Multiplication Background User's Guide](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html)\n",
    "- [Deep Dive on CUTLASS Ping-Pong GEMM Kernel](https://pytorch.org/blog/cutlass-ping-pong-gemm-kernel/)\n",
    "- [Accelerating 2D Dynamic Block Quantized Float8 GEMMs in Triton](https://pytorch.org/blog/accelerating-gemms-triton/)\n",
    "\n",
    "![](https://habrastorage.org/webt/xq/r5/8a/xqr58aw0gd6tdm-j45yqad67w1a.png)\n",
    "\n",
    "В этом задании вам нужно будет реализовать быструю операцию квантизации в per-row режиме:\n",
    "1. Для этого нужно опять же заполнить пропуски возле `YOUR CODE HERE`, пожалуйста не удаляйте эти комментарии с заданием и обозначением, это облегчает проверку\n",
    "2. Рядом с каждым пропуском есть комментарий с `# !!! TASK: ...`, который поможет разобраться что именно нужно написать\n",
    "3. На иллюстрации выше как раз показано по каким именно размерностям для матриц активаций и весов считаются scales\n",
    "4. Формула для `scales = tensor.abs().max(axis=axis) / INT8_max_value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10259127",
   "metadata": {
    "id": "10259127"
   },
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config({}, num_stages=2, num_warps=8),\n",
    "        triton.Config({}, num_stages=2, num_warps=4),\n",
    "        triton.Config({}, num_stages=2, num_warps=2),\n",
    "        triton.Config({}, num_stages=2, num_warps=1),\n",
    "     ],\n",
    "    key=['K'],\n",
    ")\n",
    "@triton.jit\n",
    "def quantize_int8_perrow_kernel(\n",
    "    fpa_ptr, a_ptr, as_ptr,\n",
    "    M, K,\n",
    "    stride_fpam, stride_fpak,\n",
    "    stride_am, stride_ak,\n",
    "    stride_asm,\n",
    "    # Meta-parameters\n",
    "    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "):\n",
    "    pid_m = tl.program_id(axis=0)\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "\n",
    "    fpa_ptrs = fpa_ptr + offs_am[:, None] * stride_fpam + offs_k[None, :] * stride_fpak\n",
    "    a_ptrs = a_ptr + offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak\n",
    "    a_max = tl.zeros((BLOCK_SIZE_M,), dtype=tl.float32)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        fpa = tl.load(fpa_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        # !!! TASK: calc maximum absolute value of each row of fpa and update a_max\n",
    "        # YOUR CODE HERE\n",
    "        a_max = ...\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        fpa_ptrs += BLOCK_SIZE_K * stride_fpak\n",
    "\n",
    "    # !!! TASK: divide a_max by max positive INT8 value\n",
    "    # YOUR CODE HERE\n",
    "    a_scale = ...\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    fpa_ptrs = fpa_ptr + offs_am[:, None] * stride_fpam + offs_k[None, :] * stride_fpak\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        fpa = tl.load(fpa_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        # !!! TASK: divide fpa by a_scale and convert to INT8\n",
    "        # YOUR CODE HERE\n",
    "        inta = ...\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        tl.store(a_ptrs, inta, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K)\n",
    "        fpa_ptrs += BLOCK_SIZE_K * stride_fpak\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "    as_offs = pid_m * BLOCK_SIZE_M * stride_asm + tl.arange(0, BLOCK_SIZE_M)\n",
    "    tl.store(as_ptr + as_offs, a_scale)\n",
    "\n",
    "\n",
    "def quantize_int8_perrow(fpa):\n",
    "    a = torch.empty(fpa.shape, device=fpa.device, dtype=torch.int8)\n",
    "    a_scale = torch.empty(fpa.shape[0], device=fpa.device, dtype=fpa.dtype)\n",
    "    M, K = fpa.shape\n",
    "    BLOCK_SIZE_M = 1\n",
    "    BLOCK_SIZE_K = triton.next_power_of_2(K)\n",
    "    grid = (M // BLOCK_SIZE_M,)\n",
    "    quantize_int8_perrow_kernel[grid](\n",
    "        fpa, a, a_scale,\n",
    "        M, K,\n",
    "        fpa.stride(0), fpa.stride(1),\n",
    "        a.stride(0), a.stride(1),\n",
    "        a_scale.stride(0),\n",
    "        BLOCK_SIZE_M, BLOCK_SIZE_K,\n",
    "    )\n",
    "    return a, a_scale\n",
    "\n",
    "\n",
    "def quantize_int8(weight, axis=0, tp_rank=0):\n",
    "    # Weight shape: [H1, H2]\n",
    "    # Scale shape: [H2]\n",
    "\n",
    "    # !!! TASK: calculate scale by taking maximum over axis and saving dims and divide on maximum positive INT8 value\n",
    "    # YOUR CODE HERE\n",
    "    scale = ...\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # !!! TASK: divide weight by scale and convert to int8\n",
    "    # YOUR CODE HERE\n",
    "    weight = ...\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # col major will accelerate i8xi8 kernel.\n",
    "    if axis == 0:\n",
    "        weight = weight.t().contiguous().t()\n",
    "    scale = scale.squeeze(axis)\n",
    "    return weight.contiguous().cuda(tp_rank), scale.contiguous().cuda(tp_rank)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3eb491",
   "metadata": {
    "id": "3e3eb491"
   },
   "source": [
    "Далее нам предстоит реализовать уже быструю операцию для per-row W8A8 GeMM:\n",
    "1. Для этого нужно опять же заполнить пропуски возле `YOUR CODE HERE`, пожалуйста не удаляйте эти комментарии с заданием и обозначением, это облегчает проверку\n",
    "2. Рядом с каждым пропуском есть комментарий с `# !!! TASK: ...`, который поможет разобраться что именно нужно написать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac639944",
   "metadata": {
    "id": "ac639944"
   },
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    "    reset_to_zero=['c_ptr']\n",
    ")\n",
    "@triton.jit\n",
    "def perrow_w8a8_matmul_kernel(\n",
    "    # Pointers to matrices\n",
    "    a_ptr, as_ptr, b_ptr, bs_ptr, c_ptr,\n",
    "    # Matrix dimensions\n",
    "    M, N, K,\n",
    "    # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "    # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`\n",
    "    # by to get the element one row down (A has M rows).\n",
    "    stride_am, stride_ak,\n",
    "    stride_asm,\n",
    "    stride_bk, stride_bn,\n",
    "    stride_bsn,\n",
    "    stride_cm, stride_cn,\n",
    "    # Meta-parameters\n",
    "    BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "    GROUP_SIZE_M: tl.constexpr, SPLIT_K: tl.constexpr,\n",
    "):\n",
    "    \"\"\"Kernel for computing the matmul C = A x B.\n",
    "    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n",
    "    \"\"\"\n",
    "    # -----------------------------------------------------------\n",
    "    # Map program ids `pid` to the block of C it should compute.\n",
    "    # This is done in a grouped ordering to promote L2 data reuse.\n",
    "    # See above `L2 Cache Optimizations` section for details.\n",
    "    pid = tl.program_id(axis=0)\n",
    "    pid_sp_k = tl.program_id(axis=1)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + (pid % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Create pointers for the first blocks of A and B.\n",
    "    # We will advance this pointer as we move in the K direction\n",
    "    # and accumulate\n",
    "    # `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\n",
    "    # `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers\n",
    "    # See above `Pointer Arithmetics` section for details\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    offs_k = pid_sp_k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "    as_ptrs = as_ptr + offs_am * stride_asm\n",
    "    bs_ptrs = bs_ptr + offs_bn * stride_bsn\n",
    "    a_scale = tl.load(as_ptrs, mask=offs_am < M, other=0.0)\n",
    "    b_scale = tl.load(bs_ptrs, mask=offs_bn < N, other=0.0)\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "\n",
    "    # !!! TASK: create accumulator of int32 dtype\n",
    "    # YOUR CODE HERE\n",
    "    accumulator = ...\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K * SPLIT_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K * SPLIT_K, other=0.0)\n",
    "        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K * SPLIT_K, other=0.0)\n",
    "        # We accumulate along the K dimension.\n",
    "\n",
    "        # !!! TASK: update accumulator with a @ b\n",
    "        # YOUR CODE HERE\n",
    "        accumulator += ...\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * SPLIT_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * SPLIT_K * stride_bk\n",
    "    # You can fuse arbitrary activation functions here\n",
    "    # while the accumulator is still in FP32!\n",
    "\n",
    "    # !!! TASK: dequantize the accumulator with a_scale and b_scale (outer product) and convert to c_ptr.dtype.element_ty\n",
    "    # YOUR CODE HERE\n",
    "    c = ...\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    if SPLIT_K == 1:\n",
    "        tl.store(c_ptrs, c, mask=c_mask)\n",
    "    else:\n",
    "        tl.atomic_add(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def matmul_int8(a, a_scale, b, b_scale, out=None):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    # Allocates output.\n",
    "    if out == None:\n",
    "        c = torch.zeros((M, N), device=a.device, dtype=torch.float16)\n",
    "    else:\n",
    "        c = out.fill_(0.)\n",
    "    grid = lambda META: (\n",
    "        triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']),\n",
    "        META['SPLIT_K'],\n",
    "    )\n",
    "    perrow_w8a8_matmul_kernel[grid](\n",
    "        a, a_scale, b, b_scale, c,\n",
    "        M, N, K,\n",
    "        a.stride(0), a.stride(1),\n",
    "        a_scale.stride(0),\n",
    "        b.stride(0), b.stride(1),\n",
    "        b_scale.stride(0),\n",
    "        c.stride(0), c.stride(1),\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "def matmul_quantize_int8(fpa, b, b_scale, out=None):\n",
    "    # !!! TASK: quantize fpa to int8 and call matmul_int8\n",
    "    # YOUR CODE HERE\n",
    "    a, a_scale = ...\n",
    "    return ...\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c3615",
   "metadata": {
    "id": "4e1c3615"
   },
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc029389",
   "metadata": {
    "id": "bc029389"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "cos = torch.nn.CosineSimilarity(0)\n",
    "\n",
    "a = inps[0][0].to(torch.float16).cuda()\n",
    "b = weight.to(torch.float16).cuda()\n",
    "\n",
    "int_a, scale_a = quantize_int8_perrow(a)\n",
    "int_b, scale_b = quantize_int8(b, axis=0)\n",
    "\n",
    "\n",
    "triton_output = matmul_int8(int_a, scale_a, int_b, scale_b)\n",
    "torch_output = torch.matmul(a, b)\n",
    "\n",
    "if (torch_output.float() - triton_output.float()).abs().mean() < 0.03 and torch.quantile((torch_output.float() - triton_output.float()).abs(), 0.95) < 0.07:\n",
    "    print(\"✅ Triton FP8 and Torch match\")\n",
    "else:\n",
    "    print(\"❌ Triton FP8 and Torch differ\")\n",
    "    print(\"Quantization cos: \", cos((int_a * scale_a.unsqueeze(1)).flatten().to(torch.float32), a.flatten().to(torch.float32)).item())\n",
    "\n",
    "    print('=' * 50)\n",
    "    print(f\"triton_output_with_fp8={triton_output}\")\n",
    "    print(f\"torch_output={torch_output}\")\n",
    "\n",
    "    print('=' * 50)\n",
    "    print(\"infs in triton:\", (triton_output).isinf().sum())\n",
    "    print(\"infs in torch:\", (torch_output).isinf().sum())\n",
    "\n",
    "    print('=' * 50)\n",
    "    print(\"Output cos:\", cos(triton_output.flatten().to(torch.float32), torch_output.flatten().to(torch.float32)).item())\n",
    "    print(((triton_output - torch_output).abs() >= 0.5).sum())\n",
    "    print(((triton_output - torch_output).abs() / (torch_output.abs() + 1e-5)))\n",
    "    assert False, \"Triton and Torch differ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d4fde",
   "metadata": {
    "id": "a36d4fde"
   },
   "source": [
    "Sanity checks on perf:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f4800",
   "metadata": {
    "id": "215f4800"
   },
   "outputs": [],
   "source": [
    "def test_perf_quantize(M: int, K: int, iters: int = 256, thr: float = 1.3):\n",
    "    torch.manual_seed(0)\n",
    "    print(f\"M: {M} K: {K}\")\n",
    "\n",
    "    a = torch.randn((M, K), device='cuda', dtype=torch.float16)\n",
    "    # warmup\n",
    "    for _ in range(10):\n",
    "        int_a, a_scale = quantize_int8(a, 1)\n",
    "        int_a, a_scale = quantize_int8_perrow(a)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    t1 = time.time()\n",
    "    for _ in range(iters):\n",
    "        int_a, a_scale = quantize_int8_perrow(a)\n",
    "    torch.cuda.synchronize()\n",
    "    t2 = time.time()\n",
    "    for _ in range(iters):\n",
    "        int_a, a_scale = quantize_int8(a, axis=1)\n",
    "    torch.cuda.synchronize()\n",
    "    t3 = time.time()\n",
    "\n",
    "    torch_time = (t3 - t2) / iters\n",
    "    triton_time = (t2 - t1) / iters\n",
    "\n",
    "    print(f\"Torch time cost: {torch_time}\")\n",
    "    print(f\"Triton time cost: {triton_time}\")\n",
    "    assert torch_time / triton_time > thr, f\"Must get at least {thr}x speedup\"\n",
    "    return triton_time, torch_time\n",
    "\n",
    "\n",
    "def test_perf_matmul_int8(M, K, N, iters: int = 512, thr: float = 0.99):\n",
    "    print(\"M: {} K: {} N: {}\".format(M, K, N))\n",
    "    torch.manual_seed(0)\n",
    "    a = torch.randn((M, K), device='cuda', dtype=torch.float16)\n",
    "    b = torch.randn((K, N), device='cuda', dtype=torch.float16).contiguous()\n",
    "    int_b, scale_b = quantize_int8(b, axis=0)\n",
    "    for _ in range(10):\n",
    "        # int_a, a_scale = quantize_int8(a, 1)\n",
    "        int_a, a_scale = quantize_int8_perrow(a)\n",
    "        triton_output = matmul_int8(int_a, a_scale, int_b, scale_b)\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    for _ in range(iters):\n",
    "        #int_a, a_scale, _ = quantize_int8(a, 1)\n",
    "        int_a, a_scale = quantize_int8_perrow(a)\n",
    "    torch.cuda.synchronize()\n",
    "    qt2 = time.time()\n",
    "    for _ in range(iters):\n",
    "        triton_output = matmul_int8(int_a, a_scale, int_b, scale_b)\n",
    "    torch.cuda.synchronize()\n",
    "    t2 = time.time()\n",
    "    quant_time = qt2 - t1\n",
    "    triton_time = t2 - qt2\n",
    "    triton_tflops = 2 * M * N * K * 1e-12 / (triton_time / iters)\n",
    "    quant_bandwith = 2 * M * K * 1e-9 / (quant_time / iters)\n",
    "    print(\"Triton time cost: {} (tflops {}) + quant: {} (bandwidth {})\".format(\n",
    "        triton_time, triton_tflops, quant_time, quant_bandwith))\n",
    "    for _ in range(10):\n",
    "        torch_output = torch.matmul(a, b)\n",
    "    torch.cuda.synchronize()\n",
    "    iters = 512\n",
    "    t1 = time.time()\n",
    "    for _ in range(iters):\n",
    "        torch_output = torch.matmul(a, b)\n",
    "    torch.cuda.synchronize()\n",
    "    t2 = time.time()\n",
    "    torch_time = t2 - t1\n",
    "    torch_tflops = 2 * M * N * K * 1e-12 / (torch_time / iters)\n",
    "    print(\"Torch time cost: {} (tflops {})\".format(t2 - t1, torch_tflops))\n",
    "\n",
    "    assert torch_time / triton_time > thr, f\"Must get at least {thr}x speedup\"\n",
    "    return triton_time, torch_time, quant_time\n",
    "\n",
    "\n",
    "def test_perf_model_layer(bs, seq_len, hidden, inter, tp, thr: float = 0.99):\n",
    "    st1 = 0\n",
    "    st2 = 0\n",
    "    st3 = 0\n",
    "    t1, t2, t3 = test_perf_matmul_int8(bs * seq_len, hidden, hidden * 3 // tp, thr=thr)\n",
    "    test_perf_quantize(bs * seq_len, hidden, thr=thr)\n",
    "    st1 += t1\n",
    "    st2 += t2\n",
    "    st3 += t3\n",
    "    t1, t2, t3 = test_perf_matmul_int8(bs * seq_len, hidden // tp, hidden, thr=thr)\n",
    "    test_perf_quantize(bs * seq_len, hidden // tp, thr=thr)\n",
    "    st1 += t1\n",
    "    st2 += t2\n",
    "    st3 += t3\n",
    "    t1, t2, t3 = test_perf_matmul_int8(bs * seq_len, hidden, inter * 2 // tp, thr=thr)\n",
    "    st1 += t1\n",
    "    st2 += t2\n",
    "    st3 += t3\n",
    "    t1, t2, t3 = test_perf_matmul_int8(bs * seq_len, inter // tp, hidden, thr=thr)\n",
    "    test_perf_quantize(bs * seq_len, inter // tp, thr=thr)\n",
    "    st1 += t1\n",
    "    st2 += t2\n",
    "    st3 += t3\n",
    "    print(\"Triton time {} Torch time {} Quant time {}\".format(st1, st2, st3))\n",
    "    assert st2 / st1 > thr, f\"Must get at least {thr}x speedup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c875e72",
   "metadata": {
    "id": "8c875e72"
   },
   "outputs": [],
   "source": [
    "bs = 32\n",
    "hidden = model.config.hidden_size\n",
    "inter  = model.config.intermediate_size\n",
    "prefill_len = 512\n",
    "decode_len = 1\n",
    "tp = 1\n",
    "\n",
    "test_perf_model_layer(bs, prefill_len, hidden, inter, tp, thr=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e80e5",
   "metadata": {
    "id": "8f7e80e5"
   },
   "source": [
    "**Note**: в последней строке видим интегральное ускорение по слою на prefill стадии в целых ~x1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10140fdb",
   "metadata": {
    "id": "10140fdb"
   },
   "outputs": [],
   "source": [
    "test_perf_model_layer(bs, decode_len, hidden, inter, tp, thr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620be8b",
   "metadata": {
    "id": "2620be8b"
   },
   "source": [
    "**Note**: в последней строке видим интегральное ускорение по слою на decode стадии, оно получилось сильно меньше (x1.03), для того чтобы выжать на decode больше уже нужна реализация на CUDA\n",
    "\n",
    "Benchmarks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18cb2b",
   "metadata": {
    "id": "be18cb2b"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def benchmark_quant_gemm(M, provider, provider_funcs):\n",
    "    N = weight.shape[0]\n",
    "    K = weight.shape[1]\n",
    "\n",
    "    fpa = prepare_a(M).to(torch.float16).cuda().contiguous()\n",
    "    fpb = weight.data.T.to(torch.float16).contiguous()\n",
    "    b, b_scale = quantize_int8(fpb, axis=0)\n",
    "\n",
    "    assert fpa.shape == (M, K), f\"{fpa.shape} != {(M, K)}\"\n",
    "    assert b.shape == (K, N), b.shape\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    ms, min_ms, max_ms = triton.testing.do_bench(lambda: provider_funcs[provider](fpa, fpb, b, b_scale), quantiles=quantiles)\n",
    "    perf = lambda ms: ms # TFlops = 2 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n",
    "\n",
    "provider_funcs = {\n",
    "    \"triton int8\": lambda fpa, fpb, b, b_scale: matmul_quantize_int8(fpa, b, b_scale),\n",
    "    \"triton fp16\": lambda fpa, fpb, b, b_scale: matmul(fpa, fpb),\n",
    "    \"cublas fp16\": lambda fpa, fpb, b, b_scale: torch.matmul(fpa, fpb)\n",
    "}\n",
    "\n",
    "configs = [\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[2 ** i for i in range(7)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[\"cublas fp16\", \"triton int8\", \"triton fp16\"],  # Label name for the lines\n",
    "        line_names=[\"cuBLAS FP16\", \"Triton INT8\", \"Triton FP16\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\"), (\"red\", \"-\")],\n",
    "        ylabel=\"ms\",  # Label name for the y-axis\n",
    "        plot_name=\"GeMV-performance-\" + (\"FP16 vs INT8\"),  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"provider_funcs\": provider_funcs},\n",
    "    ),\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[1024 * i for i in range(4, 21)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[\"cublas fp16\", \"triton int8\", \"triton fp16\"],  # Label name for the lines\n",
    "        line_names=[\"cuBLAS FP16\", \"Triton INT8\", \"Triton FP16\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\"), (\"red\", \"-\")],\n",
    "        ylabel=\"ms\",  # Label name for the y-axis\n",
    "        plot_name=\"GeMM-performance-\" + (\"FP16 vs INT8\"),  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"provider_funcs\": provider_funcs},\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "triton.testing.perf_report(configs)(benchmark_quant_gemm).run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8c54a",
   "metadata": {
    "id": "bda8c54a"
   },
   "source": [
    "**Note:** Triton FP16 побили по скорости с большим запасом, и даже смогли ускориться на prefill на больших контекстах относительно cuBLASm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e557782",
   "metadata": {
    "id": "4e557782"
   },
   "outputs": [],
   "source": [
    "provider_funcs = {\n",
    "    \"torch\": lambda a, b: quantize_int8(a),\n",
    "    \"triton\": lambda a, b: quantize_int8_perrow(a)\n",
    "}\n",
    "\n",
    "configs = [\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[2 ** i for i in range(7)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[\"torch\", \"triton\"],  # Label name for the lines\n",
    "        line_names=[\"Torch\", \"Triton\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"ms\",  # Label name for the y-axis\n",
    "        plot_name=\"Quantize-performance-\" + (\"decoding\"),  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"provider_funcs\": provider_funcs},\n",
    "    ),\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[256 * i for i in range(4, 21)],  # Different possible values for `x_name`\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        line_vals=[\"torch\", \"triton\"],  # Label name for the lines\n",
    "        line_names=[\"Torch\", \"Triton\"],  # Line styles\n",
    "        styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"ms\",  # Label name for the y-axis\n",
    "        plot_name=\"Quantize-performance-\" + (\"prefill\"),  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={\"provider_funcs\": provider_funcs},\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "triton.testing.perf_report(configs)(benchmark).run(show_plots=True, print_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da6ebe",
   "metadata": {
    "id": "16da6ebe"
   },
   "source": [
    "**Note:** реализация на торче для квантизации крайне неэффективная и квантизация на Triton-е значимо лучше и на prefill и на decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5870bf",
   "metadata": {
    "id": "da5870bf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "multi_train",
   "language": "python",
   "name": "multi_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0042f04d3b2d494d825820840c63a218": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47ec18476ab04bcaae79c83db08b30d7",
      "placeholder": "​",
      "style": "IPY_MODEL_ccf143abffb74477905aed0f5758951f",
      "value": " 1.52G/1.52G [00:26&lt;00:00, 130MB/s]"
     }
    },
    "0af77ef7255044f281689bf4e9920f52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bdfd26f0efb4065a8247d069dabb4d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c4db23a6381432280780b9937b2341a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f8c2986e92f4b0c92ad6177b6a1d772",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c593bd1741a643af9b976c0342fcbf2c",
      "value": 124
     }
    },
    "0fdb698d2ab64b50b7b7bb1361613cee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "138aad9f4f1a46419ad0eafe48f79e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef03df5b6931497198e3ded3eddadd9c",
      "placeholder": "​",
      "style": "IPY_MODEL_5d85bb2e57d64a25af8aa1feff141106",
      "value": " 548M/548M [00:10&lt;00:00, 45.2MB/s]"
     }
    },
    "139dd6e93d064808a3becdad8fe330e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f5b0082a40b47d3b6d310f371555071",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_53ba61a102514c158bbb1c257b74362a",
      "value": 665
     }
    },
    "14408ae289f74529811ac7ae09ed13ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "144d0b1a0a3a413999b37bf6e1c5ebc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "152e3682b9d2441c826b29990f5b2971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7368844d2a1144e388c45d335dd0eca6",
      "placeholder": "​",
      "style": "IPY_MODEL_d837ff85dc1142b2ad6c4aff8319a2c6",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 1.61MB/s]"
     }
    },
    "1560a393b2bf4205897c8d2930964c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1601ceee55b641f68e033b90cf4988d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1715b0af5c994f8989f636a8581d67a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b6420efada54c80bf09d6a45fc781e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f152861c7974643a5fa4f20a7421c90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "239bfaebff9f4ddfb2075b2f398b260e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24f2d38a6f7c4298b037eb8c43b12df3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27926da0475443b7b1c85bccd5664db0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_befec435a2fe4e0f9dc1207f723c411a",
       "IPY_MODEL_805cbf11c9ca438487da37b0a3e819ee",
       "IPY_MODEL_0042f04d3b2d494d825820840c63a218"
      ],
      "layout": "IPY_MODEL_924a98576dc24025b02bb27c3f428a20"
     }
    },
    "2893b20e7de647bda7830decaac73709": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aade552cfb94f50ae72c16d1bc250fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b6c5394f71149e28ba700d0f1c8926e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47bb6250c92e4138be80aed57ee97053",
       "IPY_MODEL_6b12a650addb489abc85002e49621203",
       "IPY_MODEL_f224c525afc949a6936c339d669be1c0"
      ],
      "layout": "IPY_MODEL_1b6420efada54c80bf09d6a45fc781e5"
     }
    },
    "2dbd7d6ccba34397bf58105dbc312c67": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e002b93655842f0b11f59c5d028796c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "302c35e2497e4bcca54f5233e46c2af1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_239bfaebff9f4ddfb2075b2f398b260e",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca46976dbead4772908263de47caab4e",
      "value": 1355256
     }
    },
    "31a5fd193b9641229f783381f24591cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3214ca12bb9c4549a9c41f6040d5908c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dacb7596aca947f0b25b3c6c4bbb18d5",
      "placeholder": "​",
      "style": "IPY_MODEL_869abcb0dd2b4b3982c253481f4f2964",
      "value": "tokenizer.json: 100%"
     }
    },
    "322c07a2ea50443d93b9be2ff680c078": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39f69d24716b459abd1a4549ddb9a610": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2893b20e7de647bda7830decaac73709",
      "placeholder": "​",
      "style": "IPY_MODEL_d12ec05d02e8481bb2c719e5f2e813d3",
      "value": " 718/718 [00:00&lt;00:00, 19.5kB/s]"
     }
    },
    "3b4c92a27e8046a0900d8e0068e4170c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8f4230a34294eeea443acafdfa59cce",
       "IPY_MODEL_0c4db23a6381432280780b9937b2341a",
       "IPY_MODEL_d43a013b4c284efb870badf919ca251c"
      ],
      "layout": "IPY_MODEL_322c07a2ea50443d93b9be2ff680c078"
     }
    },
    "3bb9e8c7f4c242e3926cfad4c6b1eba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb2a265bf9ce46699fe79aa6c8914789",
       "IPY_MODEL_62aae5b3b5c442b5b5bacdc57a74fe02",
       "IPY_MODEL_5824ebca0c9d427db6d762b9c84a528a"
      ],
      "layout": "IPY_MODEL_0af77ef7255044f281689bf4e9920f52"
     }
    },
    "3c2559d553c44382afd15d164cf4fa73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5d51a6e3aa643358ba4af324f676280",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83253d555da04b199d36c95ad2b0efa8",
      "value": 1042301
     }
    },
    "420a2e840bf24252a8812b16914aa6ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47bb6250c92e4138be80aed57ee97053": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80493ebab92646f38eb6f1f97dce2b57",
      "placeholder": "​",
      "style": "IPY_MODEL_d49c799a7dfd414db2e6dc162dca34d6",
      "value": "generation_config.json: 100%"
     }
    },
    "47ec18476ab04bcaae79c83db08b30d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cbf8fc1f86b4ce3a8fd9a221f941466": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f048a3e1d534a7ab8c37b7276ffe31b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f526d697e7e4454a5283a2f7938e831": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3214ca12bb9c4549a9c41f6040d5908c",
       "IPY_MODEL_302c35e2497e4bcca54f5233e46c2af1",
       "IPY_MODEL_c4b19cffce4941f895a57181dc1ad1aa"
      ],
      "layout": "IPY_MODEL_4f048a3e1d534a7ab8c37b7276ffe31b"
     }
    },
    "4f9255668f9848b19f11db9c49b068c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4fe7f5b3c48541ac8af0ac29eacc51ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "50bf10a82c4b484f882f1ec199a657a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53ba61a102514c158bbb1c257b74362a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "57ffd579807043119696059cf26d2833": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aade552cfb94f50ae72c16d1bc250fe",
      "max": 548105171,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8b8789d978c4a99b85db921bdfba03c",
      "value": 548105171
     }
    },
    "5824ebca0c9d427db6d762b9c84a528a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1601ceee55b641f68e033b90cf4988d2",
      "placeholder": "​",
      "style": "IPY_MODEL_31a5fd193b9641229f783381f24591cd",
      "value": " 26.0/26.0 [00:00&lt;00:00, 2.17kB/s]"
     }
    },
    "5a174f53fee443d88f47a09a9f84c746": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50bf10a82c4b484f882f1ec199a657a1",
      "placeholder": "​",
      "style": "IPY_MODEL_f676d51df9fe422fbd47d323fde16e5c",
      "value": "config.json: 100%"
     }
    },
    "5c80b5ea4fea4c699647330a7dbe604a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d52d41b06d34bc18207b113d5113117": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d85bb2e57d64a25af8aa1feff141106": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6092bcf6f35a407e870b56d87fc862b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61f89044a34a4b31836ad6170c0150ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "62aae5b3b5c442b5b5bacdc57a74fe02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69f4758d39e240dd92e47da74dffb9dc",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f9255668f9848b19f11db9c49b068c2",
      "value": 26
     }
    },
    "6573e3da701544639b0d7dbd3f88d3ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69467dcaf6414f7ba30b232828fa84ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69f4758d39e240dd92e47da74dffb9dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a4ee693b33f49e2809b42aba198894c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b12a650addb489abc85002e49621203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69467dcaf6414f7ba30b232828fa84ae",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1715b0af5c994f8989f636a8581d67a3",
      "value": 124
     }
    },
    "6bdf3456ad8842bbbcc2fde169663224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af6484a8307e47f9841f88fecb633d4e",
      "placeholder": "​",
      "style": "IPY_MODEL_0fdb698d2ab64b50b7b7bb1361613cee",
      "value": "model.safetensors: 100%"
     }
    },
    "7057be52e08f4ff4a314372676c1089e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bdfd26f0efb4065a8247d069dabb4d4",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61f89044a34a4b31836ad6170c0150ca",
      "value": 456318
     }
    },
    "7368844d2a1144e388c45d335dd0eca6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73cd83bc17c948108a31d9960aac5cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c5a22fa943548b89735a5005374fb64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f1f3742754143d3900f64337d664549": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbd7d6ccba34397bf58105dbc312c67",
      "placeholder": "​",
      "style": "IPY_MODEL_abb02237fd344b3c9dcbb2ccee9fe2fb",
      "value": "vocab.json: 100%"
     }
    },
    "80493ebab92646f38eb6f1f97dce2b57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "805cbf11c9ca438487da37b0a3e819ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6092bcf6f35a407e870b56d87fc862b4",
      "max": 1519984962,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1560a393b2bf4205897c8d2930964c31",
      "value": 1519984962
     }
    },
    "828c7b590e4d42629d4d2a88eeb0b473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83253d555da04b199d36c95ad2b0efa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84be30df6615409c93fa49fb8804f07f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8538f7ddd7544576b5f9d5768a5f5a25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cbf8fc1f86b4ce3a8fd9a221f941466",
      "placeholder": "​",
      "style": "IPY_MODEL_73cd83bc17c948108a31d9960aac5cde",
      "value": " 665/665 [00:00&lt;00:00, 64.7kB/s]"
     }
    },
    "869abcb0dd2b4b3982c253481f4f2964": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b57098825b14807b8302bdae37c5e77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f152861c7974643a5fa4f20a7421c90",
      "placeholder": "​",
      "style": "IPY_MODEL_e43907de99e0411f8586b7e3fee2695e",
      "value": "merges.txt: 100%"
     }
    },
    "8c298c7f037b408bab7e4c0632fa8c50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f5b0082a40b47d3b6d310f371555071": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f8c2986e92f4b0c92ad6177b6a1d772": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90dad4abc4b445938d83a1b002ffba74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "924a98576dc24025b02bb27c3f428a20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9304f07a754747608b94a94782cac7cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2f14985d19446708cdccfdb3840e7cc",
       "IPY_MODEL_9fc58d97c2ef4a8d97ff244da41a2af9",
       "IPY_MODEL_39f69d24716b459abd1a4549ddb9a610"
      ],
      "layout": "IPY_MODEL_420a2e840bf24252a8812b16914aa6ec"
     }
    },
    "9a76b12ad07642468ddd6be7569a227d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f1f3742754143d3900f64337d664549",
       "IPY_MODEL_3c2559d553c44382afd15d164cf4fa73",
       "IPY_MODEL_152e3682b9d2441c826b29990f5b2971"
      ],
      "layout": "IPY_MODEL_5c80b5ea4fea4c699647330a7dbe604a"
     }
    },
    "9fc58d97c2ef4a8d97ff244da41a2af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e002b93655842f0b11f59c5d028796c",
      "max": 718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4fe7f5b3c48541ac8af0ac29eacc51ac",
      "value": 718
     }
    },
    "a2715701a4484e93aec04a7a5d653dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a41ad52f4f864f7bbd62915d72d5fc36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa7b4cdab70d46eb8620b4cfb017bc02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abb02237fd344b3c9dcbb2ccee9fe2fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af6484a8307e47f9841f88fecb633d4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc81089726b74514b543a3d571126c58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "befec435a2fe4e0f9dc1207f723c411a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c5a22fa943548b89735a5005374fb64",
      "placeholder": "​",
      "style": "IPY_MODEL_dbe50e6947f04a9baea2e0d6b88f9ef7",
      "value": "model.safetensors: 100%"
     }
    },
    "c2d35eb971794ee6806d936bbb5a35f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2f14985d19446708cdccfdb3840e7cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6573e3da701544639b0d7dbd3f88d3ad",
      "placeholder": "​",
      "style": "IPY_MODEL_bc81089726b74514b543a3d571126c58",
      "value": "config.json: 100%"
     }
    },
    "c4b19cffce4941f895a57181dc1ad1aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14408ae289f74529811ac7ae09ed13ec",
      "placeholder": "​",
      "style": "IPY_MODEL_828c7b590e4d42629d4d2a88eeb0b473",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 5.86MB/s]"
     }
    },
    "c593bd1741a643af9b976c0342fcbf2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c5d51a6e3aa643358ba4af324f676280": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca46976dbead4772908263de47caab4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cb2a265bf9ce46699fe79aa6c8914789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2d35eb971794ee6806d936bbb5a35f3",
      "placeholder": "​",
      "style": "IPY_MODEL_a41ad52f4f864f7bbd62915d72d5fc36",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "ccf143abffb74477905aed0f5758951f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d12ec05d02e8481bb2c719e5f2e813d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d43a013b4c284efb870badf919ca251c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84be30df6615409c93fa49fb8804f07f",
      "placeholder": "​",
      "style": "IPY_MODEL_f2c432aad70f4b829a6d71f00a33729d",
      "value": " 124/124 [00:00&lt;00:00, 13.7kB/s]"
     }
    },
    "d49c799a7dfd414db2e6dc162dca34d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7563830a1ff4abd8bc3c0305c12efb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d837ff85dc1142b2ad6c4aff8319a2c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dacb7596aca947f0b25b3c6c4bbb18d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbe50e6947f04a9baea2e0d6b88f9ef7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e43907de99e0411f8586b7e3fee2695e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8b8789d978c4a99b85db921bdfba03c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec48462fc5c541bd8d38490a918d4a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b57098825b14807b8302bdae37c5e77",
       "IPY_MODEL_7057be52e08f4ff4a314372676c1089e",
       "IPY_MODEL_fd4bdc7c2d6b4872b00140929e311415"
      ],
      "layout": "IPY_MODEL_d7563830a1ff4abd8bc3c0305c12efb2"
     }
    },
    "ef03df5b6931497198e3ded3eddadd9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efe247cd494e411db56b3d084140eedc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bdf3456ad8842bbbcc2fde169663224",
       "IPY_MODEL_57ffd579807043119696059cf26d2833",
       "IPY_MODEL_138aad9f4f1a46419ad0eafe48f79e9e"
      ],
      "layout": "IPY_MODEL_90dad4abc4b445938d83a1b002ffba74"
     }
    },
    "f224c525afc949a6936c339d669be1c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24f2d38a6f7c4298b037eb8c43b12df3",
      "placeholder": "​",
      "style": "IPY_MODEL_a2715701a4484e93aec04a7a5d653dbd",
      "value": " 124/124 [00:00&lt;00:00, 7.53kB/s]"
     }
    },
    "f2c432aad70f4b829a6d71f00a33729d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f676d51df9fe422fbd47d323fde16e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8f4230a34294eeea443acafdfa59cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d52d41b06d34bc18207b113d5113117",
      "placeholder": "​",
      "style": "IPY_MODEL_144d0b1a0a3a413999b37bf6e1c5ebc2",
      "value": "generation_config.json: 100%"
     }
    },
    "fc726b7ae72d4b15994a7052299b452c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a174f53fee443d88f47a09a9f84c746",
       "IPY_MODEL_139dd6e93d064808a3becdad8fe330e0",
       "IPY_MODEL_8538f7ddd7544576b5f9d5768a5f5a25"
      ],
      "layout": "IPY_MODEL_6a4ee693b33f49e2809b42aba198894c"
     }
    },
    "fd4bdc7c2d6b4872b00140929e311415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c298c7f037b408bab7e4c0632fa8c50",
      "placeholder": "​",
      "style": "IPY_MODEL_aa7b4cdab70d46eb8620b4cfb017bc02",
      "value": " 456k/456k [00:00&lt;00:00, 29.0MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
