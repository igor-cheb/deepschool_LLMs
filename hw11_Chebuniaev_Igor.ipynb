{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6831fe55",
   "metadata": {},
   "source": [
    "# KV Cache - 10 баллов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29b7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045cc82",
   "metadata": {},
   "source": [
    "Представим, что у нас есть очень простая мини-LLM:\n",
    "1. Она эмбеддит токены\n",
    "2. Считает аттеншн (обычный, не multihead) токенов друг с другом с causal mask (не смотрит в будущее!)\n",
    "3. После этого выходы attention подаются в линейный слой для получения распределеняи по словарю\n",
    "\n",
    "На примере такой модели давайте попробуем имплементировать KV-Cache.\n",
    "\n",
    "Ниже за вас написан метод forward - этот метод это обычный forward нейросети, который считает attention всех токенов со всеми токенами.\n",
    "\n",
    "Вам же нужно имплементировать метод forward_kv_cache, который принимает:\n",
    "* x - тензор размерности \\[batch, seq_len = 1\\]\n",
    "* prev_output - выход модели с предыдущего шага типа Output\n",
    "\n",
    "Метод forward_kv_cache должен выполнять следующие действия:\n",
    "1. Эмбеддинг токена x\n",
    "2. Проекция x в QKV\n",
    "3. Расширение k_cache и v_cache из prev_ouptut k/v проекциями x\n",
    "4. Подсчет аттеншена между q_x и k_cache и v_cache\n",
    "5. Конкатенация аттеншена в prev_output.attention_weights\n",
    "6. Возврат logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before generation tensor([[1, 3, 0]])\n",
      "After generation no cache tensor([[1, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0]])\n",
      "After generation kv cache tensor([[1, 3, 0, 2, 6, 1, 6, 1, 6, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Output:\n",
    "    logits: torch.Tensor = None\n",
    "    k_cache: torch.Tensor = None\n",
    "    v_cache: torch.Tensor = None\n",
    "    attn_weights: torch.Tensor = None\n",
    "    \n",
    "\n",
    "\n",
    "class SimpleAttentionLLM(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.lin = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        q = self.W_Q(x)\n",
    "        k = self.W_K(x)\n",
    "        v = self.W_V(x)\n",
    "        \n",
    "        attn_scores = torch.matmul(q, k.permute(0, 2, 1))\n",
    "        mask = torch.tril(torch.ones_like(attn_scores))\n",
    "        attn_scores = attn_scores.masked_fill(~mask.bool(), -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=2)\n",
    "        weights_V = torch.matmul(attn_weights, v)\n",
    "        logits = self.lin(weights_V)\n",
    "        return Output(\n",
    "            logits=logits,\n",
    "            k_cache=k,\n",
    "            v_cache=v,\n",
    "            attn_weights=attn_weights # batch, seq_len, seq_len\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward_kv_cache(self, x, prev_output):\n",
    "        # эмбеддинг токена x\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # 1. Проецируем x в q, k, v\n",
    "        q = self.W_Q(x)\n",
    "        k = self.W_K(x)\n",
    "        v = self.W_V(x)\n",
    "        \n",
    "        # print(f\"{q.shape=}\")\n",
    "        # print(f\"{k.shape=}\")\n",
    "\n",
    "        # берем старый кэш\n",
    "        k_cache = prev_output.k_cache\n",
    "        v_cache = prev_output.v_cache\n",
    "\n",
    "        # расширяем его состояниями k, v последнего токена\n",
    "        # с помощью torch.cat\n",
    "        k_cache_new = torch.cat(tensors=(k_cache, k), dim=1)\n",
    "        v_cache_new = torch.cat(tensors=(v_cache, v), dim=1)\n",
    "        \n",
    "        # считаем attention_score, то есть матричное умножение между q и k_cache_new\n",
    "        \n",
    "        attn_scores = q @ k_cache_new.permute(0, 2, 1)\n",
    "    \n",
    "        \n",
    "        # считаем softmax\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        # домножаем softmax на V\n",
    "        \n",
    "        # print(f\"{attn_scores.shape=}\")\n",
    "        # print(f\"{v_cache_new.shape=}\")\n",
    "        weights_V = attn_weights @ v_cache_new\n",
    "        logits = self.lin(weights_V)\n",
    "        \n",
    "        batch = x.size(0)\n",
    "        seq_len = k_cache.size(1)\n",
    "        \n",
    "        attn_weights_old = prev_output.attn_weights\n",
    "        zeros_right = torch.zeros(batch, seq_len, 1)\n",
    "        # добавляем нули в аттеншене так, чтобы у старых токенов был нулевой аттеншн на новый токен\n",
    "        attn_weights_all = torch.cat((attn_weights_old, zeros_right), dim=2)\n",
    "        # Добавляем аттеншн текущего нового токена по старым\n",
    "        attn_weights_all = torch.cat((attn_weights_all, attn_weights), dim=1)\n",
    "        \n",
    "        return Output(\n",
    "            logits=logits,\n",
    "            k_cache=k_cache_new,\n",
    "            v_cache=v_cache_new,\n",
    "            attn_weights=attn_weights_all\n",
    "        )\n",
    "        \n",
    "torch.manual_seed(1)\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "d_model = 128\n",
    "vocab_size = 7\n",
    "\n",
    "layer = SimpleAttentionLLM(d_model, vocab_size)\n",
    "for param in layer.parameters():\n",
    "    nn.init.normal_(param)\n",
    "\n",
    "x = torch.randint(0, 7, (batch_size, seq_len))\n",
    "x_copy = x.clone()\n",
    "\n",
    "print(\"Before generation\", x)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        outputs = layer(x)\n",
    "        logits = outputs.logits\n",
    "        # берем последний токен, т.к. по нему предсказываем!\n",
    "        next_token = logits[:, -1].argmax(dim=1, keepdim=True)\n",
    "        x = torch.cat((x, next_token), dim=1) # добавляем новый токен по размерности seq_len\n",
    "\n",
    "no_cache_output = outputs\n",
    "print(\"After generation no cache\", x)\n",
    "\n",
    "\n",
    "x = x_copy.clone()\n",
    "final_tokens = x.clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # prefill\n",
    "    outputs = layer(x)\n",
    "    logits = outputs.logits\n",
    "    # берем последний токен, т.к. по нему предсказываем!\n",
    "    next_token = logits[:, -1].argmax(dim=1, keepdim=True)\n",
    "    # обратите внимание, что раньше было 10 шагов!\n",
    "    final_tokens = torch.cat((final_tokens, next_token), dim=1)\n",
    "    for i in range(9):\n",
    "        outputs = layer.forward_kv_cache(next_token, outputs)\n",
    "        next_token = outputs.logits[:, -1].argmax(dim=1, keepdim=True)\n",
    "        final_tokens = torch.cat((final_tokens, next_token), dim=1)\n",
    "    \n",
    "print(\"After generation kv cache\", final_tokens)\n",
    "\n",
    "cache_outputs = outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Before generation tensor([[1, 3, 0]])\n",
    "After generation no cache tensor([[1, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0]])\n",
    "After generation kv cache tensor([[1, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62b506",
   "metadata": {},
   "source": [
    "Выведем матрицы attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "305f232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Attention kv cache')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(no_cache_output.attn_weights[0])\n",
    "axes[0].set_title(\"Attention no cache\")\n",
    "axes[1].imshow(cache_outputs.attn_weights[0])\n",
    "axes[1].set_title(\"Attention kv cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vllm triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e45fc6",
   "metadata": {},
   "source": [
    "По возможности данное задание необходимо выполнять на сервере, чтобы было удобно запускать параллельно фреймворк и нагрузочное тестирование. Для удобства работы в jupyter сделан следующий трюк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "\n",
    "def start_vllm_server():\n",
    "    # This function will run the `vllm` server command\n",
    "    cmd = [\"vllm\", \"serve\", \"unsloth/gemma-2b-it\", \"--dtype\", \"half\"]\n",
    "    subprocess.run(cmd)\n",
    "\n",
    "\n",
    "server_process = multiprocessing.Process(target=start_vllm_server)\n",
    "server_process.start()\n",
    "time.sleep(60)\n",
    "print(\"we are probably ready\")\n",
    "\n",
    "import requests\n",
    "\n",
    "r = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
    "                  \"model\": \"unsloth/gemma-2b-it\",\n",
    "                  \"prompt\": \"Hello there\",\n",
    "                  \"max_tokens\": 20,\n",
    "                  \"temperature\": 0.8\n",
    "              })\n",
    "print(r.json())\n",
    "print(r.json()[\"choices\"][0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31f5df",
   "metadata": {},
   "source": [
    "# Нагрузочное тестирование - 25 баллов\n",
    "\n",
    "20 баллов - узнать, сколько запросов в секунду выдержит VLLM сервинг модели при ограничении latency в 5 секунд.\n",
    "Можно использовать самописную функцию через multiprocessing/threading, можно использовать любой готовый инструмент.\n",
    "\n",
    "В качестве пейлоадов предлагается брать тексты длины 100-128 и генерировать к ним не более 10 токенов. Сами пейлоады можно взять из любого датасета, например https://huggingface.co/datasets/Intel/orca_dpo_pairs.\n",
    "\n",
    "Об аргументах vllm serve можно почитать в документации https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html\n",
    "\n",
    "\n",
    "5 баллов - если сможете посчитать на этом пейлоаде ttft - time to first token, то есть сколько занимает prefill стадия генерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e05e253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08c334b3",
   "metadata": {},
   "source": [
    "# Часть 2\n",
    "Далее предоставлено 2 варианта выполнения задания. Баллы будут начисляться только на один из них\n",
    "## Вариант 1. Квантизация - 15 баллов\n",
    "Квантизируйте модель в VLLM любым доступным способом, напишите, как сократились затраты памяти и как изменилась скорость инференса. Обязательно укажите, на какой видеокарте проводились замеры!\n",
    "Не забудьте про то, что квантизировать можно и kv cache.\n",
    "\n",
    "Внимательно проверьте и убедитесь, что ваш ускоритель поддержан в https://docs.vllm.ai/en/latest/quantization/supported_hardware.html\n",
    "\n",
    "## Вариант 2. Батчевалка - 15 баллов\n",
    "Предлагается написать сервер на питоне, который поддерживал бы батчевание запросов.\n",
    "\n",
    "Сервер принимает POST запрос с телом вида\n",
    "\n",
    "```json\n",
    "{\"text\": \"Hello there\"}\n",
    "```\n",
    "\n",
    "\n",
    "Необходимо написать сервер, который:\n",
    "1. Имел бы возможность работать с несколькими клиентами за раз (не блокировался бы на обработку одного запроса). Для этого можно использовать async, gevent, треды и т.д.\n",
    "2. Использовал бы батчовую обработку следующим образом:\n",
    "если пришло несколько запросов (для примера 2)\n",
    "\n",
    "```json\n",
    "запрос 1\n",
    "{\"text\": \"Hello there \"}\n",
    "запрос 2\n",
    "{\"text\": \"handsome\"}\n",
    "```\n",
    "\n",
    "то каждый клиент получал бы в ответ конкатенацию этих запросов (в произвольном порядке), т.е. оба клиента получили бы ответ\n",
    "```json\n",
    "{\"text\": \"Hello there handsome\"}\n",
    "или\n",
    "{\"text\": \"handsomeHello there \"}\n",
    "```\n",
    "\n",
    "Сервер должен иметь 2 конфигурируемых параметра:\n",
    "1. Максимальный размер батча, который он может обработать\n",
    "2. Максимальное время ожидания, которое ждет сэмпл перед обработкой. Т.е. если у нас батч размера 5, а у нас всего один сэмпл, и прошло максимальное время ожидания - этот сэмпл попадает в батч один и обрабатывается один.\n",
    "\n",
    "Для хранения данных в очереди можно использовать queue.Queue или любой другой удобный способ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe94205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_train",
   "language": "python",
   "name": "multi_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
