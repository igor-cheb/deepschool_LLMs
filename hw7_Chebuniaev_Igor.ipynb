{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d481b105",
   "metadata": {
    "collapsed": true,
    "id": "d481b105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.16\n",
      "  Downloading langchain-0.3.16-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting langchain-core==0.3.32\n",
      "  Downloading langchain_core-0.3.32-py3-none-any.whl (412 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.4/412.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai==0.3.2\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-together==0.3.0\n",
      "  Downloading langchain_together-0.3.0-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-llms-together==0.2.0\n",
      "  Downloading llama_index_llms_together-0.2.0-py3-none-any.whl (2.1 kB)\n",
      "Collecting smolagents==1.13.0\n",
      "  Downloading smolagents-1.13.0-py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting together==1.5.5\n",
      "  Downloading together-1.5.5-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.51.3\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting pydantic==2.7.4\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (3.11.12)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.3.16)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.16)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain==0.3.16)\n",
      "  Downloading langsmith-0.3.32-py3-none-any.whl (358 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.2/358.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (9.0.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.32)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain-core==0.3.32) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain-core==0.3.32) (4.12.2)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai==0.3.2)\n",
      "  Downloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain-openai==0.3.2)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-llms-together==0.2.0)\n",
      "  Downloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai-like<0.3.0,>=0.2.0 (from llama-index-llms-together==0.2.0)\n",
      "  Downloading llama_index_llms_openai_like-0.2.0-py3-none-any.whl (3.1 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (0.29.2)\n",
      "Requirement already satisfied: rich>=13.9.4 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (13.9.4)\n",
      "Requirement already satisfied: jinja2>=3.1.4 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (3.1.5)\n",
      "Requirement already satisfied: pillow<11.2.0,>=11.0.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (11.1.0)\n",
      "Collecting markdownify>=0.14.1 (from smolagents==1.13.0)\n",
      "  Downloading markdownify-1.1.0-py3-none-any.whl (13 kB)\n",
      "Collecting duckduckgo-search>=6.3.7 (from smolagents==1.13.0)\n",
      "  Downloading duckduckgo_search-8.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting python-dotenv (from smolagents==1.13.0)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (8.1.8)\n",
      "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together==1.5.5)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (19.0.1)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (4.67.1)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (0.9.0)\n",
      "Collecting huggingface-hub>=0.28.0 (from smolagents==1.13.0)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from transformers==4.51.3) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from transformers==4.51.3) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from transformers==4.51.3) (0.5.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from pydantic==2.7.4) (0.7.0)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic==2.7.4)\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (1.18.3)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search>=6.3.7->smolagents==1.13.0)\n",
      "  Downloading primp-0.15.0-cp38-abi3-macosx_10_12_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml>=5.3.0 (from duckduckgo-search>=6.3.7->smolagents==1.13.0)\n",
      "  Downloading lxml-5.3.2-cp310-cp310-macosx_10_9_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.28.0->smolagents==1.13.0) (2024.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from jinja2>=3.1.4->smolagents==1.13.0) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.32) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.16)\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.16) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain==0.3.16)\n",
      "  Downloading orjson-3.10.16-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.16) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain==0.3.16)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-macosx_10_9_x86_64.whl (788 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.7/788.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (3.9.1)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.16)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (0.9.0)\n",
      "Collecting wrapt (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-macosx_10_9_x86_64.whl (38 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.0 (from llama-index-llms-openai-like<0.3.0,>=0.2.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from markdownify>=0.14.1->smolagents==1.13.0) (4.13.3)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from markdownify>=0.14.1->smolagents==1.13.0) (1.17.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (1.8.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (314 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from rich>=13.9.4->smolagents==1.13.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from rich>=13.9.4->smolagents==1.13.0) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.16) (3.1.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (1.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from beautifulsoup4<5,>=4.9->markdownify>=0.14.1->smolagents==1.13.0) (2.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.16) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.16) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents==1.13.0) (0.1.2)\n",
      "Requirement already satisfied: joblib in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (1.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (1.0.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: filetype, dirtyjson, zstandard, wrapt, tenacity, python-dotenv, pydantic-core, primp, orjson, marshmallow, lxml, jsonpatch, jiter, eval-type-backport, async-timeout, tiktoken, pydantic, markdownify, huggingface-hub, duckduckgo-search, deprecated, dataclasses-json, smolagents, openai, langsmith, transformers, together, llama-index-core, langchain-core, llama-index-llms-openai, langchain-text-splitters, langchain-openai, llama-index-llms-openai-like, langchain-together, langchain, llama-index-llms-together\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: orjson\n",
      "    Found existing installation: orjson 3.9.10\n",
      "    Uninstalling orjson-3.9.10:\n",
      "      Successfully uninstalled orjson-3.9.10\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.6\n",
      "    Uninstalling pydantic-2.10.6:\n",
      "      Successfully uninstalled pydantic-2.10.6\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.29.2\n",
      "    Uninstalling huggingface-hub-0.29.2:\n",
      "      Successfully uninstalled huggingface-hub-0.29.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic-yaml 1.3.0 requires importlib-metadata, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed async-timeout-4.0.3 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 duckduckgo-search-8.0.1 eval-type-backport-0.2.2 filetype-1.2.0 huggingface-hub-0.30.2 jiter-0.9.0 jsonpatch-1.33 langchain-0.3.16 langchain-core-0.3.32 langchain-openai-0.3.2 langchain-text-splitters-0.3.5 langchain-together-0.3.0 langsmith-0.3.32 llama-index-core-0.11.23 llama-index-llms-openai-0.2.16 llama-index-llms-openai-like-0.2.0 llama-index-llms-together-0.2.0 lxml-5.3.2 markdownify-1.1.0 marshmallow-3.26.1 openai-1.75.0 orjson-3.10.16 primp-0.15.0 pydantic-2.7.4 pydantic-core-2.18.4 python-dotenv-1.1.0 smolagents-1.13.0 tenacity-8.5.0 tiktoken-0.9.0 together-1.5.5 transformers-4.51.3 wrapt-1.17.2 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain==0.3.16 langchain-core==0.3.32 langchain-openai==0.3.2 langchain-together==0.3.0 llama-index-llms-together==0.2.0 smolagents==1.13.0 together==1.5.5 transformers==4.51.3 numpy pydantic==2.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ro4W8om8_c9R",
   "metadata": {
    "id": "Ro4W8om8_c9R"
   },
   "source": [
    "**После установки окружения, если возникает ошибка с numpy - перезапустите ноутбук.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610f8418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dff7c4",
   "metadata": {
    "id": "22dff7c4"
   },
   "source": [
    "# Tools and Agents\n",
    "В этом домашнем задании мы разберемся в том, как работают function calls, как их видит и обрабатывает модель и разберемся с несколькими популярными фреймворками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33c44059",
   "metadata": {
    "id": "33c44059"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "import requests\n",
    "from together import Together\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619698e9",
   "metadata": {
    "id": "619698e9"
   },
   "source": [
    "# Function calls - 20 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A4I9HliFWlcz",
   "metadata": {
    "id": "A4I9HliFWlcz"
   },
   "source": [
    "## Клиент - 5 баллов\n",
    "\n",
    "В предыдущем задании мы разобрались с походами в API - мы ходили к провайдеру с помощью библиотеки requests и каждый раз собирали данные для посылки руками.\n",
    "\n",
    "Многие провайдеры предоставляют удобный интерфейс для взаимодействия ввиде библиотеки для python. Таки библиотеки есть и у [openai](https://platform.openai.com/docs/api-reference/responses/create) и у [Together](https://github.com/togethercomputer/together-python?tab=readme-ov-file#chat-completions). Многие провайдеры специально делают свой API совместимым с openai, например так сделал [deepseek](https://api-docs.deepseek.com/)\n",
    "\n",
    "\n",
    "Давайте познакомимся с Together клиентом в этом задании. Для этого давайте используем функцию `client.chat.completions.create`. Также давайте добавим опции сэмплинга, которые в этой функции поддержаны. Их можно посылать и в запросах через requests, но мы здесь и далее будем пользоваться клиентом.\n",
    "* top_k = 100\n",
    "* temperature = 0.5\n",
    "* top_p = 0.9\n",
    "* repetition_penalty = 1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3f3931a",
   "metadata": {
    "id": "a3f3931a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Вставьте свой ключ из https://api.together.ai/\n",
    "# и не забудьте удалить его перед посылкой\n",
    "#или подайте его через переменную окружения\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "API_KEY = \"4b3c0ae4d2a4967007029571545378b611c58fdcdad808abb154b07fb0993ab7\"\n",
    "# ---- Конец кода ----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88dc9341",
   "metadata": {
    "id": "88dc9341"
   },
   "outputs": [],
   "source": [
    "client = Together(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b88e3ef8",
   "metadata": {
    "id": "b88e3ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United Kingdom (Britain) has multiple capitals for its four constituent countries. \n",
      "\n",
      "1. England's capital is London.\n",
      "2. Scotland's capital is Edinburgh.\n",
      "3. Wales' capital is Cardiff.\n",
      "4. Northern Ireland's capital is Belfast.\n",
      "\n",
      "So, it depends on which part of Britain you're referring to. If you're talking about the UK as a whole, London is often considered the de facto capital.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of Britain?\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "# docs\n",
    "# https://github.com/togethercomputer/together-python?tab=readme-ov-file#chat-completions\n",
    "sampling_parameters = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"repetition_penalty\": 1.05,\n",
    "    \"top_p\": 0.9,\n",
    "    \"top_k\": 100,\n",
    "}\n",
    "response = client.chat.completions.create(model=model_name, messages=messages, **sampling_parameters) # ваш код здесь\n",
    "\n",
    "response_text: str = json.loads(response.model_dump_json())['choices'][0]['message']['content']\n",
    "print(response_text)\n",
    "# ---- Конец кода ----\n",
    "\n",
    "assert \"london\" in response_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IRlfNmmlk08u",
   "metadata": {
    "id": "IRlfNmmlk08u"
   },
   "source": [
    "## Structured output - 5 баллов\n",
    "\n",
    "На лекции мы узнали, что можно попросить модель напрямую сгенерировать структурированный выход несколькими способами:\n",
    "1. Попросить модель сгенерировать данные в нужном формате\n",
    "2. Использовать какой-либо алгоритм выбора токенов для соответствия заданной структуре.\n",
    "\n",
    "\n",
    "Давайте попробуем оба этих подхода.\n",
    "\n",
    "1. Попросите модель с помощью промптинга сгенерировать ингредиенты для какого-нибудь блюда\n",
    "2. Используйте для этой же задачи [structured output / constrained generation](https://docs.together.ai/docs/json-mode) с помощью Pydantic-классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "m57YqNZxlcMc",
   "metadata": {
    "id": "m57YqNZxlcMc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В свободном формате получилось сгенерировать json\n",
      "{'actionItems': [{'name': 'Chicken breast', 'quantity': '4'}, {'name': 'Butter', 'quantity': '2 tablespoons'}, {'name': 'Mushrooms', 'quantity': '1 cup'}, {'name': 'Onions', 'quantity': '1/2 cup'}, {'name': 'Garlic', 'quantity': '2 cloves'}, {'name': 'Salt', 'quantity': 'to taste'}, {'name': 'Black pepper', 'quantity': 'to taste'}, {'name': 'All-purpose flour', 'quantity': '1 cup'}, {'name': 'Eggs', 'quantity': '2'}, {'name': 'Breadcrumbs', 'quantity': '1 cup'}, {'name': 'Grated cheese', 'quantity': '1/2 cup'}, {'name': 'Fresh parsley', 'quantity': 'chopped'}, {'name': 'Ham or prosciutto', 'quantity': '4 slices'}]}\n",
      "Успешно сгенерировался json в structured output\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "# в качестве блюда можно выбрать \"english breakfast\"\n",
    "\n",
    "# здесь составьте промпт в свободном формате\n",
    "messages = [{'role': 'user', 'content': 'Please list ingridients for a chicken Kiev in Json format like so: \\\n",
    "               {\\\"ingridient 1\\\": \"<your answer>\", \\\"ingridient 2\\\": \\\"<your answer>\\\"}. \\\n",
    "               No yapping, only json.'}]\n",
    "response_freeform = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    ")\n",
    "response_text: str = json.loads(response_freeform.model_dump_json())['choices'][0]['message']['content']\n",
    "# print(response_text)\n",
    "\n",
    "try:\n",
    "  json.loads(response_text)\n",
    "  print(\"В свободном формате получилось сгенерировать json\")\n",
    "except:\n",
    "  print(\"В свободном формате не получилось сгенерировать json, но это не ошибка, не нужно подгонять промпт\")\n",
    "\n",
    "# https://docs.together.ai/docs/json-mode\n",
    "class RecipeItem(BaseModel):\n",
    "  name: str = Field(description=\"Name of the ingridient\")\n",
    "  quantity: str = Field(description=\"Quantity of said ingridient\")\n",
    "\n",
    "class RecipeModel(BaseModel):\n",
    "    actionItems: list[RecipeItem] = Field(description=\"List of recipe ingridients\")\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    "    response_format={\n",
    "      \"type\": \"json_object\",\n",
    "      \"schema\": RecipeModel.model_json_schema(),\n",
    "    }\n",
    ")\n",
    "response_text: str = response.choices[0].message.content\n",
    "try:\n",
    "  print(json.loads(response_text))\n",
    "  print(\"Успешно сгенерировался json в structured output\")\n",
    "except:\n",
    "  print(\"Здесь должен был сгенерироваться валидный json\")\n",
    "\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5758f",
   "metadata": {
    "id": "08d5758f"
   },
   "source": [
    "## Function Call pipeline - 10 баллов\n",
    "\n",
    "Давайте теперь посмотрим, как можно использовать tools в связке с моделями. У нас есть функция, которая входит в базу данных и получает информацию о юзере. Базы данных, конечно же, у нас никакой нет, но у нас есть некоторая функция, которая эмулирует это поведение, так что давайте попробуем ее описать.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dd5090a",
   "metadata": {
    "id": "2dd5090a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job': 'DeepSchool Founder', 'city': 'Novosibirsk'}\n"
     ]
    }
   ],
   "source": [
    "def get_user_info_from_db(person_name: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Get a dictionary with information about person\n",
    "    Args:\n",
    "      person_name: Name of the person to look for\n",
    "    Returns:\n",
    "      Dictionary with information about person\n",
    "    \"\"\"\n",
    "    database = {\n",
    "        \"ilya\": {\n",
    "            \"job\": \"Software Developer\",\n",
    "            \"pets\": \"dog\",\n",
    "        },\n",
    "        \"farruh\": {\n",
    "            \"job\": \"Senior Data & Solution Architect\",\n",
    "            \"hobby\": \"travelling, hiking\",\n",
    "        },\n",
    "        \"timur\": {\n",
    "            \"job\": \"DeepSchool Founder\",\n",
    "            \"city\": \"Novosibirsk\",\n",
    "        }\n",
    "    }\n",
    "    no_info = {\"err\": f\"No info about {person_name}\"}\n",
    "    return database.get(person_name.lower(), no_info)\n",
    "\n",
    "print(get_user_info_from_db(\"Timur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e8052",
   "metadata": {
    "id": "bf7e8052"
   },
   "source": [
    "Давайте попробуем описать эту функцию в формате json, чтобы модель могла ее увидеть!\n",
    "Заполните поля в определении дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbb3a3cf",
   "metadata": {
    "id": "dbb3a3cf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "get_user_info_from_db_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_user_info_from_db\",\n",
    "        \"description\": \"emulates query to a database\", # Напишите, что функция делает своими словами\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"person_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"name of a person\"# Опишите смысл аргумента\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"person_name\"] # укажите обязательные аргументы для функции\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980a9be",
   "metadata": {
    "id": "e980a9be"
   },
   "source": [
    "Давайте пошлем наш запрос в модель. Для этого воспользуемся клиентом и функцией\n",
    "`client.chat.completions.create`. Не забудьте передать в поле tools список список из инструментов (список json).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2cdaebf",
   "metadata": {
    "id": "b2cdaebf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCalls(id='call_n35jyq4hzmwnzzmzk4cmdhjz', type='function', function=FunctionCall(name='get_user_info_from_db', arguments='{\"person_name\":\"Ilya\"}'), index=0)]\n",
      "\n",
      "name='get_user_info_from_db' arguments='{\"person_name\":\"Ilya\"}'\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-7B-Instruct-Turbo\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "response = client.chat.completions.create(\n",
    "    tools=[get_user_info_from_db_tool],\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    ") # допишите вызов функции\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "assert len(response.choices[0].message.tool_calls) > 0\n",
    "\n",
    "print(response.choices[0].message.tool_calls)\n",
    "print()\n",
    "print(response.choices[0].message.tool_calls[0].function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b870a67",
   "metadata": {
    "id": "3b870a67"
   },
   "source": [
    "Если все хорошо, то мы получили ответ от модели со списком `response.choices[0].message.tool_calls`, который содержит в себе название функции и словарь с ее аргументами.\n",
    "\n",
    "Если бы мы не использовали клиент, то нам пришлось бы самим по правилам (регулярными выражениями) определять, что модель вызвала инструмент, но клиент берет эту работу за нас.\n",
    "\n",
    "Давайте теперь напишем код, который может с помощью значения tool_calls вызывать функцию с правильными аргументами.\n",
    "\n",
    "Здесь нам поможет FUNCTION_REGISTRY и то, что параметры в функцию можно передавать как словарь, например так\n",
    "```python\n",
    "def foo(a, b, c):\n",
    "    print(a, b, c)\n",
    "\n",
    "obj = {'b':10, 'c':'lee'}\n",
    "\n",
    "foo(100, **obj)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92feaf07",
   "metadata": {
    "id": "92feaf07"
   },
   "outputs": [],
   "source": [
    "from together.types.chat_completions import FunctionCall\n",
    "\n",
    "FUNCTION_REGISTRY = {\"get_user_info_from_db\": get_user_info_from_db}\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "def use_function_call(tool_call: FunctionCall):\n",
    "  # Ваш код здесь\n",
    "  # 1. Берем имя функции и по ней получаем функцию из FUNCTION_REGISTRY\n",
    "  func = FUNCTION_REGISTRY[tool_call.function.name]\n",
    "  # 2. Загружаем аргументы\n",
    "  args = json.loads(tool_call.function.arguments)\n",
    "  # 3. Вызываем функцию с аргументами и возвращаем результат\n",
    "  return func(**args)\n",
    "\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "assert use_function_call(response.choices[0].message.tool_calls[0]) == get_user_info_from_db(\"Ilya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuh8culATfml",
   "metadata": {
    "id": "fuh8culATfml"
   },
   "source": [
    "Теперь давайте добавим ответ инструмента с ролью tool и сгенерируем моделью финальный ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "Y2vZpJlzTe-K",
   "metadata": {
    "id": "Y2vZpJlzTe-K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, Ilya is a Software Developer and he has a dog as a pet. Is there anything specific you would like to know about Ilya or his job?\n"
     ]
    }
   ],
   "source": [
    "# ---- Ваш код здесь ----\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "]\n",
    "# Давайте положим в историю диалога ответ инструмента с ролью tool\n",
    "messages.append({\"role\": \"tool\", \"content\": json.dumps(use_function_call(response.choices[0].message.tool_calls[0]))})\n",
    "# вызовем новую генерацию\n",
    "response = client.chat.completions.create(\n",
    "    tools=[get_user_info_from_db_tool],\n",
    "    model=model_name,\n",
    "    messages=messages\n",
    "    ) #\n",
    "response_text: str = response.choices[0].message.content\n",
    "# ---- Конец кода ----\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VqXB3KxLg-St",
   "metadata": {
    "id": "VqXB3KxLg-St"
   },
   "source": [
    "Теперь давайте посмотрим, как выглядел промпт на самом деле, для этого нужно использовать функцию `tokenizer.apply_chat_template` и в аргументе tools передать список функций, которые модель может использовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "XN3dnJnpgb5s",
   "metadata": {
    "id": "XN3dnJnpgb5s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant\n",
      "\n",
      "# Tools\n",
      "\n",
      "You may call one or more functions to assist with the user query.\n",
      "\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"get_user_info_from_db\", \"description\": \"emulates query to a database\", \"parameters\": {\"type\": \"object\", \"properties\": {\"person_name\": {\"type\": \"string\", \"description\": \"name of a person\"}}, \"required\": [\"person_name\"]}}}\n",
      "</tools>\n",
      "\n",
      "For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
      "<tool_call>\n",
      "{\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What do you know about Ilya?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B\")\n",
    "\n",
    "messages = [\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "{\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "]\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "full_prompt = tokenizer.apply_chat_template(\n",
    "    conversation=messages,\n",
    "    tools=[get_user_info_from_db_tool],\n",
    "    tokenize=False\n",
    ")\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907c917",
   "metadata": {
    "id": "e907c917"
   },
   "source": [
    "# Использование библиотек - 10 баллов\n",
    "\n",
    "Теперь, когда мы руками прошли весь пути обработки function call можно посмотреть уже на готовые инструменты.\n",
    "Мы много чего сделали руками:\n",
    "1. Писали описание функции\n",
    "2. Обрабатывали ответ\n",
    "3. Вызывали функцию\n",
    "4. Возвращали все это в модель\n",
    "\n",
    "Давайте теперь посмотрим, как оно работает в библиотеках!\n",
    "\n",
    "**NB** - библиотеки развиваются и вполне возможно, что к концу курса те интерфейсы, которые мы используем в этом домашнем задании будут уже неактуальны, но я уверен, что знаний и принципов, полученных из этих заданий хватит, чтобы адаптироваться к будущим вызовам!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b964f9",
   "metadata": {
    "id": "51b964f9"
   },
   "source": [
    "## LangChain - 5 баллов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ef83e32",
   "metadata": {
    "id": "5ef83e32"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b08ae",
   "metadata": {
    "id": "0a7b08ae"
   },
   "source": [
    "Давайте ознакомимся с langchain-интеграцией together.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7f75658",
   "metadata": {
    "id": "f7f75658"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOGETHER_API_KEY\"] = API_KEY\n",
    "\n",
    "llm = ChatTogether(\n",
    "    model=model_name,\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d548c4e",
   "metadata": {
    "id": "9d548c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a few notable individuals named Ilya, but without more context, it's difficult to specify which one you're referring to. Here are a few prominent people named Ilya:\n",
      "\n",
      "1. **Ilya Muromets**: A legendary hero from Russian folklore, known for his strength and adventures.\n",
      "\n",
      "2. **Ilya I (Ilie I)**: A historical figure, the first Prince of Moldavia, who ruled from 1345 to 1374.\n",
      "\n",
      "3.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d698905",
   "metadata": {
    "id": "1d698905"
   },
   "source": [
    "Теперь, когда мы разобрались, как базово работать с langchain, давайте попробуем добавить инструментов. Чтобы нам было не так скучно, давайте напишем новую функцию, которая считает \"волшебную операцию\".\n",
    "\n",
    "Эта функция принимает 2 строки, возвращает строку строку b в обратном порядке, сконкатенированную со строкой a. Допишите эту функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb6976bf",
   "metadata": {
    "id": "bb6976bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Returns inverted string b concatenated with string a.', 'properties': {'a': {'title': 'A', 'type': 'string'}, 'b': {'title': 'B', 'type': 'string'}}, 'required': ['a', 'b'], 'title': 'magic_operation_tool', 'type': 'object'}\n",
      "Good\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "@tool # декоратор\n",
    "def magic_operation_tool(a: str, b: str) -> str: # аннотации типов\n",
    "    \"\"\"Returns inverted string b concatenated with string a.\"\"\" # docstring\n",
    "    return b[::-1] + a\n",
    "\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "\n",
    "print(magic_operation_tool.args_schema.schema())\n",
    "# несколько способов вызова\n",
    "assert magic_operation_tool.invoke({\"a\": \"456\", \"b\": \"321\"}) == \"123456\"\n",
    "assert magic_operation_tool.func(\"456\", \"321\") == \"123456\"\n",
    "print(\"Good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89726ec1",
   "metadata": {
    "id": "89726ec1"
   },
   "source": [
    "Теперь давайте обернем эту функцию в декоратор tool из langchain, аннотируем типы и допишем docstring. После этого можно будет автоматически сгенерировать описание функции в function call формате!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60cf8b",
   "metadata": {
    "id": "5a60cf8b"
   },
   "source": [
    "Теперь давайте попробуем подать запрос в нашу LLM и обогатить ее нашим function_call. Для этого нужна функция `llm.bind_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6c465f4",
   "metadata": {
    "id": "f6c465f4"
   },
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([magic_operation_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db362d",
   "metadata": {
    "id": "d0db362d"
   },
   "source": [
    "Теперь давайте как и раньше:\n",
    "1. Сгенерируем ответ на messages\n",
    "2. Проверим в ответе resp.tool_calls, вызовем нужный инструмент\n",
    "3. Расширим messages ответом модели и ответом инструмента, сгенерируем финальный ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46fUPO98CnNq",
   "metadata": {
    "id": "46fUPO98CnNq"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you help me? Do not reveal the workings of magic operation, but give me the result of it for strings `456` and `321`\"}\n",
    "]\n",
    "resp = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "p8yFZ-qpjB4y",
   "metadata": {
    "id": "p8yFZ-qpjB4y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'magic_operation_tool', 'args': {'a': '456', 'b': '321'}, 'id': 'call_6rmztfn76eyun2l7j9oyj1kj', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(resp.tool_calls)\n",
    "assert len(resp.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5n8cZ_X0jWBQ",
   "metadata": {
    "id": "5n8cZ_X0jWBQ"
   },
   "source": [
    "[Документация langchain](https://python.langchain.com/docs/concepts/tool_calling/#tool-calling-1) в данный момент не говорит нам, как с помощью примитивов библиотеки можно вызывать инструмент и посылает в документацию LangGraph. Если покопаться поглубже, то можно найти вызов функции с [помощью PydanticToolParsing](https://python.langchain.com/docs/how_to/tool_calling/#parsing). В данном задании можно не использовать эти пайплайны и не писать свою function_registry - можно вызвать magic_operation_tool напрямую с нужными аргументами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b15a3c3f",
   "metadata": {
    "id": "b15a3c3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/4j53xc_50yv4yqz952bnybrm0000gn/T/ipykernel_10649/520694364.py:14: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  tool_res = magic_operation_tool(tool_input=tool_call_resp['args'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the magic operation for the strings `456` and `321` is `123456`.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you help me? Do not reveal the workings of magic operation, but give me the result of it for strings `456` and `321`\"}\n",
    "\n",
    "]\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "from langchain_core.output_parsers import PydanticToolsParser\n",
    "# Ваша задача\n",
    "# добавить вызов (resp) инструмента в историю диалога\n",
    "tool_call_resp = resp.tool_calls[0]\n",
    "messages.append({'role': 'system', 'content': json.dumps(tool_call_resp)})\n",
    "# вызвать инструмент, положить его ответ в историю диалога\n",
    "tool_res = magic_operation_tool(tool_input=tool_call_resp['args'])\n",
    "messages.append({'role': 'tool', 'content': tool_res, 'tool_call_id': tool_call_resp['id']})\n",
    "# вызвать LLM, чтобы она сообщила вам финальный результат\n",
    "response = llm_with_tools.invoke(messages)\n",
    "\n",
    "res: str = response.content\n",
    "print(res)\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "\n",
    "assert \"123456\" in res and len(messages) == 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feb1a5b",
   "metadata": {
    "id": "3feb1a5b"
   },
   "source": [
    "## LlamaIndex - 5 баллов\n",
    "\n",
    "Аналогичный инструмент LlamaIndex. Давайте попробуем сразу собрать ReActAgent с помощью этой библиотеки, который поможет нам в использовании магической операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e6485db",
   "metadata": {
    "id": "9e6485db"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.together import TogetherLLM\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfef1b75",
   "metadata": {
    "id": "cfef1b75"
   },
   "outputs": [],
   "source": [
    "llm = TogetherLLM(model=model_name, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea9b3e",
   "metadata": {
    "id": "b6ea9b3e"
   },
   "source": [
    "Инструменты в llamaindex заполняются почти как в langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b6a47a7",
   "metadata": {
    "id": "4b6a47a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolMetadata(description='magic_operation_tool(a: str, b: str) -> str\\nReturns inverted string b concatenated with string a.', name='magic_operation_tool', fn_schema=<class 'llama_index.core.tools.utils.magic_operation_tool'>, return_direct=False)\n"
     ]
    }
   ],
   "source": [
    "# ---- Ваш код здесь ----\n",
    "# аннтоируйте выходные и выходные типы, допишите docstring и реализацию функциии\n",
    "def magic_operation_tool(a: str, b: str) -> str: # аннотации типов\n",
    "    \"\"\"Returns inverted string b concatenated with string a.\"\"\" # docstring\n",
    "    return b[::-1] + a\n",
    "\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "magic_operation_tool_llamaindex = FunctionTool.from_defaults(fn=magic_operation_tool)\n",
    "print(magic_operation_tool_llamaindex.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73306d2",
   "metadata": {
    "id": "a73306d2"
   },
   "source": [
    "Давайте создадим ReActAgent: ему нужно передать tools, llm, memory=None и verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84236969",
   "metadata": {
    "id": "84236969"
   },
   "outputs": [],
   "source": [
    "# ---- Ваш код здесь ----\n",
    "agent = ReActAgent(tools=[magic_operation_tool_llamaindex], llm=llm, memory=None, verbose=True) # допишите конструктор\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12a204d8",
   "metadata": {
    "id": "12a204d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 22061ded-d6ef-497d-9e58-aa0b20f87141. Step input: Can you help me? Do not reveal the workings of magic operation, but give me the result of it for strings `456` and `321`\n",
      "\u001b[1;3;38;5;200mThought: The user wants the result of the magic operation on the strings '456' and '321'. I need to use the magic_operation_tool for this.\n",
      "Action: magic_operation_tool\n",
      "Action Input: {'a': '456', 'b': '321'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 123456\n",
      "\u001b[0m> Running step a81813dc-b17b-41ac-b80d-93249b55d74f. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The result of the magic operation on the strings '456' and '321' is '123456'.\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"The result of the magic operation on the strings '456' and '321' is '123456'.\", sources=[ToolOutput(content='123456', tool_name='magic_operation_tool', raw_input={'args': (), 'kwargs': {'a': '456', 'b': '321'}}, raw_output='123456', is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Can you help me? Do not reveal the workings of magic operation, but give me the result of it for strings `456` and `321`\"\n",
    "agent.chat(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725419ad",
   "metadata": {
    "id": "725419ad"
   },
   "source": [
    "# Финансовый агент - 10\n",
    "\n",
    "Настала пора сделать своего агента!\n",
    "Попробуем сделать финансового аналитика. Требования следующие:\n",
    "бот должен по запросу данных о какой-либо компании смотреть самые большие изменения цены ее акций за последний месяц, после чего бот должен объяснить, с какой новостью это связано.\n",
    "\n",
    "Предлагается не строить сложную систему с классификаторами, а отдать всю сложную работу агенту. Давайте посмотрим, какие API нам доступны.\n",
    "\n",
    "Первым делом получение котировок - для этого нам поможет библиотека yfinance. По названию компании и периоду отчетности можно посмотреть открывающие цены на момент открытия и закрытия биржи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a00d2f0",
   "metadata": {
    "id": "5a00d2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (0.2.55)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (2025.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-03-18 00:00:00-04:00</th>\n",
       "      <td>214.160004</td>\n",
       "      <td>212.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-19 00:00:00-04:00</th>\n",
       "      <td>214.220001</td>\n",
       "      <td>215.240005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-20 00:00:00-04:00</th>\n",
       "      <td>213.990005</td>\n",
       "      <td>214.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-21 00:00:00-04:00</th>\n",
       "      <td>211.559998</td>\n",
       "      <td>218.270004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-24 00:00:00-04:00</th>\n",
       "      <td>221.000000</td>\n",
       "      <td>220.729996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-25 00:00:00-04:00</th>\n",
       "      <td>220.770004</td>\n",
       "      <td>223.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-26 00:00:00-04:00</th>\n",
       "      <td>223.509995</td>\n",
       "      <td>221.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-27 00:00:00-04:00</th>\n",
       "      <td>221.389999</td>\n",
       "      <td>223.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-28 00:00:00-04:00</th>\n",
       "      <td>221.669998</td>\n",
       "      <td>217.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31 00:00:00-04:00</th>\n",
       "      <td>217.009995</td>\n",
       "      <td>222.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01 00:00:00-04:00</th>\n",
       "      <td>219.809998</td>\n",
       "      <td>223.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-02 00:00:00-04:00</th>\n",
       "      <td>221.320007</td>\n",
       "      <td>223.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-03 00:00:00-04:00</th>\n",
       "      <td>205.539993</td>\n",
       "      <td>203.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-04 00:00:00-04:00</th>\n",
       "      <td>193.889999</td>\n",
       "      <td>188.380005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-07 00:00:00-04:00</th>\n",
       "      <td>177.199997</td>\n",
       "      <td>181.460007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-08 00:00:00-04:00</th>\n",
       "      <td>186.699997</td>\n",
       "      <td>172.419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-09 00:00:00-04:00</th>\n",
       "      <td>171.949997</td>\n",
       "      <td>198.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-10 00:00:00-04:00</th>\n",
       "      <td>189.070007</td>\n",
       "      <td>190.419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-11 00:00:00-04:00</th>\n",
       "      <td>186.100006</td>\n",
       "      <td>198.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-14 00:00:00-04:00</th>\n",
       "      <td>211.440002</td>\n",
       "      <td>202.520004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-15 00:00:00-04:00</th>\n",
       "      <td>201.860001</td>\n",
       "      <td>202.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-16 00:00:00-04:00</th>\n",
       "      <td>198.360001</td>\n",
       "      <td>194.270004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-17 00:00:00-04:00</th>\n",
       "      <td>197.199997</td>\n",
       "      <td>196.979996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open       Close\n",
       "Date                                             \n",
       "2025-03-18 00:00:00-04:00  214.160004  212.690002\n",
       "2025-03-19 00:00:00-04:00  214.220001  215.240005\n",
       "2025-03-20 00:00:00-04:00  213.990005  214.100006\n",
       "2025-03-21 00:00:00-04:00  211.559998  218.270004\n",
       "2025-03-24 00:00:00-04:00  221.000000  220.729996\n",
       "2025-03-25 00:00:00-04:00  220.770004  223.750000\n",
       "2025-03-26 00:00:00-04:00  223.509995  221.529999\n",
       "2025-03-27 00:00:00-04:00  221.389999  223.850006\n",
       "2025-03-28 00:00:00-04:00  221.669998  217.899994\n",
       "2025-03-31 00:00:00-04:00  217.009995  222.130005\n",
       "2025-04-01 00:00:00-04:00  219.809998  223.190002\n",
       "2025-04-02 00:00:00-04:00  221.320007  223.889999\n",
       "2025-04-03 00:00:00-04:00  205.539993  203.190002\n",
       "2025-04-04 00:00:00-04:00  193.889999  188.380005\n",
       "2025-04-07 00:00:00-04:00  177.199997  181.460007\n",
       "2025-04-08 00:00:00-04:00  186.699997  172.419998\n",
       "2025-04-09 00:00:00-04:00  171.949997  198.850006\n",
       "2025-04-10 00:00:00-04:00  189.070007  190.419998\n",
       "2025-04-11 00:00:00-04:00  186.100006  198.149994\n",
       "2025-04-14 00:00:00-04:00  211.440002  202.520004\n",
       "2025-04-15 00:00:00-04:00  201.860001  202.139999\n",
       "2025-04-16 00:00:00-04:00  198.360001  194.270004\n",
       "2025-04-17 00:00:00-04:00  197.199997  196.979996"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "stock = yf.Ticker(\"AAPL\") # посмотрим котировки APPLE\n",
    "df = stock.history(period=\"1mo\")\n",
    "df[[\"Open\", \"Close\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d2b6b",
   "metadata": {
    "id": "026d2b6b"
   },
   "source": [
    "Для поиска новостей нам поможет https://newsapi.org/\n",
    "Можно легко получить свой ключ за короткую регистрацию, дается 1000 запросов в день, каждый запрос может включать в себя ключевое слово и промежуток дат. По бесплатному апи ключу дается ровно 1 месяц, что нам подходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "639e4310",
   "metadata": {
    "id": "639e4310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple says it’ll use Apple Maps Look Around photos to train AI\n",
      "Sometime earlier this month, Apple updated a section of its website that discloses how it collects and uses imagery for Apple Maps’ Look Around feature, which is similar to Google Maps’ Street View, as spotted by 9to5Mac. A newly added paragraph reveals that,…\n"
     ]
    }
   ],
   "source": [
    "api_key = \"92d4b4314ea141caac845fbb91eb6b0a\" # ваш API ключ здесь!\n",
    "api_template = \"https://newsapi.org/v2/everything?q={keyword}&apiKey={api_key}&from={date_from}\"\n",
    "\n",
    "# дата должна быть не ранее месяца назад, иначе ошибка\n",
    "articles = requests.get(api_template.format(keyword=\"Apple\", api_key=api_key, date_from=\"2025-03-21\")).json()\n",
    "\n",
    "for article in articles[\"articles\"]:\n",
    "    if article[\"title\"] != \"[Removed]\":\n",
    "        print(article[\"title\"])\n",
    "        print(article[\"description\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "237514f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e3a83d47-83b9-421a-8287-77fe4859d517. Step input: Can you help me? I need to know what happened to TSLA stock over the last month.\n",
      "\u001b[1;3;38;5;200mThought: The user wants to know about the TSLA stock over the last month. I should first find the date with the maximum price difference for TSLA to identify any significant events.\n",
      "Action: max_price_diff\n",
      "Action Input: {'stock_name': 'TSLA'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: {'date': '2025-04-09', 'max_diff': 47.510009765625}\n",
      "\u001b[0m> Running step 8f8f659d-0e40-4c4d-9a33-099922cbf5cf. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have found that the date with the maximum price difference for TSLA was on 2025-04-09 with a difference of 47.51. Now I should find relevant news articles for TSLA on this date to understand what caused this significant change.\n",
      "Action: get_relevant_news\n",
      "Action Input: {'stock_name': 'TSLA', 'date': '2025-04-09'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [{'title': 'India Bars BYD Entry as Minister Signals Preference for Tesla, Citing Trade Concerns', 'description': 'India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns.', 'date': '2025-04-08T15:10:57Z'}, {'title': \"Trump's auto tariffs will have a 'significant' impact on Tesla, Elon Musk says\", 'description': 'President Donald Trump’s new auto tariffs will have a “significant” effect on Tesla (TSLA), CEO Elon Musk says. Read more...', 'date': '2025-03-27T13:33:00Z'}, {'title': 'People are ditching their Teslas in huge numbers as the Elon Musk backlash grows', 'description': 'Tesla (TSLA) owners are ditching their vehicles in record numbers, as consumer interest in the brand appears to be waning.Read more...', 'date': '2025-03-21T16:30:00Z'}, {'title': 'Tesla just reported its worst quarterly sales in years as Elon Musk courts controversy', 'description': 'Tesla (TSLA) delivered slightly more than 336,000 electric vehicles between January and March, far below Wall Street’s already low expectationsRead more...', 'date': '2025-04-02T13:30:00Z'}, {'title': \"Nearly every Cybertruck has been recalled. Here's all the other car recalls this month you should know about\", 'description': 'Tesla (TSLA) issued its eighth Cybertruck recall last week, this time over faulty exterior panels that could become a road hazard. Read more...', 'date': '2025-03-24T12:45:00Z'}]\n",
      "\u001b[0m> Running step 16049bcf-4aa5-43f8-9620-8dd37c092821. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The significant price difference in TSLA stock on 2025-04-09 was likely due to the news that India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns. This news might have affected the market perception of TSLA as a competitor in the Indian market. Additionally, there were other news articles around that time, such as Tesla reporting its worst quarterly sales in years and facing controversies, which could have also impacted the stock price.\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='The significant price difference in TSLA stock on 2025-04-09 was likely due to the news that India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns. This news might have affected the market perception of TSLA as a competitor in the Indian market. Additionally, there were other news articles around that time, such as Tesla reporting its worst quarterly sales in years and facing controversies, which could have also impacted the stock price.', sources=[ToolOutput(content=\"{'date': '2025-04-09', 'max_diff': 47.510009765625}\", tool_name='max_price_diff', raw_input={'args': (), 'kwargs': {'stock_name': 'TSLA'}}, raw_output={'date': '2025-04-09', 'max_diff': 47.510009765625}, is_error=False), ToolOutput(content='[{\\'title\\': \\'India Bars BYD Entry as Minister Signals Preference for Tesla, Citing Trade Concerns\\', \\'description\\': \\'India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns.\\', \\'date\\': \\'2025-04-08T15:10:57Z\\'}, {\\'title\\': \"Trump\\'s auto tariffs will have a \\'significant\\' impact on Tesla, Elon Musk says\", \\'description\\': \\'President Donald Trump’s new auto tariffs will have a “significant” effect on Tesla (TSLA), CEO Elon Musk says. Read more...\\', \\'date\\': \\'2025-03-27T13:33:00Z\\'}, {\\'title\\': \\'People are ditching their Teslas in huge numbers as the Elon Musk backlash grows\\', \\'description\\': \\'Tesla (TSLA) owners are ditching their vehicles in record numbers, as consumer interest in the brand appears to be waning.Read more...\\', \\'date\\': \\'2025-03-21T16:30:00Z\\'}, {\\'title\\': \\'Tesla just reported its worst quarterly sales in years as Elon Musk courts controversy\\', \\'description\\': \\'Tesla (TSLA) delivered slightly more than 336,000 electric vehicles between January and March, far below Wall Street’s already low expectationsRead more...\\', \\'date\\': \\'2025-04-02T13:30:00Z\\'}, {\\'title\\': \"Nearly every Cybertruck has been recalled. Here\\'s all the other car recalls this month you should know about\", \\'description\\': \\'Tesla (TSLA) issued its eighth Cybertruck recall last week, this time over faulty exterior panels that could become a road hazard. Read more...\\', \\'date\\': \\'2025-03-24T12:45:00Z\\'}]', tool_name='get_relevant_news', raw_input={'args': (), 'kwargs': {'stock_name': 'TSLA', 'date': '2025-04-09'}}, raw_output=[{'title': 'India Bars BYD Entry as Minister Signals Preference for Tesla, Citing Trade Concerns', 'description': 'India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns.', 'date': '2025-04-08T15:10:57Z'}, {'title': \"Trump's auto tariffs will have a 'significant' impact on Tesla, Elon Musk says\", 'description': 'President Donald Trump’s new auto tariffs will have a “significant” effect on Tesla (TSLA), CEO Elon Musk says. Read more...', 'date': '2025-03-27T13:33:00Z'}, {'title': 'People are ditching their Teslas in huge numbers as the Elon Musk backlash grows', 'description': 'Tesla (TSLA) owners are ditching their vehicles in record numbers, as consumer interest in the brand appears to be waning.Read more...', 'date': '2025-03-21T16:30:00Z'}, {'title': 'Tesla just reported its worst quarterly sales in years as Elon Musk courts controversy', 'description': 'Tesla (TSLA) delivered slightly more than 336,000 electric vehicles between January and March, far below Wall Street’s already low expectationsRead more...', 'date': '2025-04-02T13:30:00Z'}, {'title': \"Nearly every Cybertruck has been recalled. Here's all the other car recalls this month you should know about\", 'description': 'Tesla (TSLA) issued its eighth Cybertruck recall last week, this time over faulty exterior panels that could become a road hazard. Read more...', 'date': '2025-03-24T12:45:00Z'}], is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32f75126",
   "metadata": {
    "id": "32f75126"
   },
   "source": [
    "Очень много статей заблокированы и имеют название `[Removed]`, нужно их отфильтровать. В оставшихся статьях будем брать только title (заголовок) и description (описание или краткий пересказ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9378f6",
   "metadata": {
    "id": "cc9378f6"
   },
   "source": [
    "Вам необходимо реализовать [ReAct Agent](https://react-lm.github.io/). Особенность этого агента заключается в том, что он вначале формирует мысль, а потом вызывает действие (function call) для достижения какой-либо цели.\n",
    "\n",
    "Что нужно сделать:\n",
    "1. Описать и реализовать function call для определения, в какой день была самая большая разница в цене акций в момент открытия и закрытия биржи. Функция получает один аргумент - название акций компании (например AAPL для Apple), а выдает словарь с 2мя полями: с датой максимальной разницы в ценах и самой разницей в ценах.\n",
    "2. Описать и реализовать function call для получения 5 релевантных новостей о компании. В качестве аргумента принимаются название компании и дата. Ваша задача - сходить в newsapi, получить новости и вернуть 5 случайных новостей, которые произошли не позже чем день торгов. Если новостей меньше 5, то верните столько, сколько получится.\n",
    "3. После этого агент должен вернуть ответ, в котором постарается аргументировать изменения в цене.\n",
    "\n",
    "\n",
    "Реализовывать агента можно любым удобным способом, в том числе взять готовые имплементации.\n",
    "1. [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/agent/react_agent/) - вдобавок можно посмотреть предыдущее задание, где он уже используется.\n",
    "2. [Langchain/Langgraph](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#code)\n",
    "3. Написать полностью свою реализацию\n",
    "\n",
    "\n",
    "Не забудьте, что очень важно описать задачу в промпте: нужно сказать, какие цели у агента и что он должен сделать. У функций должны быть говорящие описания, чтобы LLM без лишних проблем поняла, какие есть функции и когда их использовать. По всем вопросам можно обращаться в наш телеграм-чат в канал \"Tools & Agents\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2b0dac5",
   "metadata": {
    "id": "a2b0dac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2025-04-09', 'max_diff': 26.900009155273438}\n",
      "> Running step 80e528bd-5f20-4feb-ab06-ced0e16a14f5. Step input: Can you help me? What happened to TSLA stock over the last month?\n",
      "\u001b[1;3;38;5;200mThought: The user wants to know what happened to TSLA stock over the last month. I need to find the date with the maximum price difference for TSLA to understand if there was a significant event.\n",
      "Action: max_price_diff\n",
      "Action Input: {'stock_name': 'TSLA'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: {'date': '2025-04-09', 'max_diff': 47.510009765625}\n",
      "\u001b[0m> Running step 17d12ed7-7564-4a75-9fd3-3df646e64ae7. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have the date with the maximum price difference for TSLA. Now I need to find out if there were any relevant news articles on that date to understand the cause of the price difference.\n",
      "Action: get_relevant_news\n",
      "Action Input: {'stock_name': 'TSLA', 'date': '2025-04-09'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [{'title': 'India Bars BYD Entry as Minister Signals Preference for Tesla, Citing Trade Concerns', 'description': 'India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns.', 'date': '2025-04-08T15:10:57Z'}, {'title': \"Trump's auto tariffs will have a 'significant' impact on Tesla, Elon Musk says\", 'description': 'President Donald Trump’s new auto tariffs will have a “significant” effect on Tesla (TSLA), CEO Elon Musk says. Read more...', 'date': '2025-03-27T13:33:00Z'}, {'title': 'People are ditching their Teslas in huge numbers as the Elon Musk backlash grows', 'description': 'Tesla (TSLA) owners are ditching their vehicles in record numbers, as consumer interest in the brand appears to be waning.Read more...', 'date': '2025-03-21T16:30:00Z'}, {'title': 'Tesla just reported its worst quarterly sales in years as Elon Musk courts controversy', 'description': 'Tesla (TSLA) delivered slightly more than 336,000 electric vehicles between January and March, far below Wall Street’s already low expectationsRead more...', 'date': '2025-04-02T13:30:00Z'}, {'title': \"Nearly every Cybertruck has been recalled. Here's all the other car recalls this month you should know about\", 'description': 'Tesla (TSLA) issued its eighth Cybertruck recall last week, this time over faulty exterior panels that could become a road hazard. Read more...', 'date': '2025-03-24T12:45:00Z'}]\n",
      "\u001b[0m> Running step 4cd8412a-f053-4edb-979a-2753510ae5a8. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The TSLA stock experienced a significant price difference on 2025-04-09, with a maximum difference of 47.51. While there isn't a direct news article on that exact date, a notable event that could have influenced the stock price was Tesla's worst quarterly sales in years, reported on 2025-04-02. Additionally, there were other events like regulatory concerns in India and recalls of the Cybertruck that could have impacted the stock price over the last month.\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response=\"The TSLA stock experienced a significant price difference on 2025-04-09, with a maximum difference of 47.51. While there isn't a direct news article on that exact date, a notable event that could have influenced the stock price was Tesla's worst quarterly sales in years, reported on 2025-04-02. Additionally, there were other events like regulatory concerns in India and recalls of the Cybertruck that could have impacted the stock price over the last month.\", sources=[ToolOutput(content=\"{'date': '2025-04-09', 'max_diff': 47.510009765625}\", tool_name='max_price_diff', raw_input={'args': (), 'kwargs': {'stock_name': 'TSLA'}}, raw_output={'date': '2025-04-09', 'max_diff': 47.510009765625}, is_error=False), ToolOutput(content='[{\\'title\\': \\'India Bars BYD Entry as Minister Signals Preference for Tesla, Citing Trade Concerns\\', \\'description\\': \\'India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns.\\', \\'date\\': \\'2025-04-08T15:10:57Z\\'}, {\\'title\\': \"Trump\\'s auto tariffs will have a \\'significant\\' impact on Tesla, Elon Musk says\", \\'description\\': \\'President Donald Trump’s new auto tariffs will have a “significant” effect on Tesla (TSLA), CEO Elon Musk says. Read more...\\', \\'date\\': \\'2025-03-27T13:33:00Z\\'}, {\\'title\\': \\'People are ditching their Teslas in huge numbers as the Elon Musk backlash grows\\', \\'description\\': \\'Tesla (TSLA) owners are ditching their vehicles in record numbers, as consumer interest in the brand appears to be waning.Read more...\\', \\'date\\': \\'2025-03-21T16:30:00Z\\'}, {\\'title\\': \\'Tesla just reported its worst quarterly sales in years as Elon Musk courts controversy\\', \\'description\\': \\'Tesla (TSLA) delivered slightly more than 336,000 electric vehicles between January and March, far below Wall Street’s already low expectationsRead more...\\', \\'date\\': \\'2025-04-02T13:30:00Z\\'}, {\\'title\\': \"Nearly every Cybertruck has been recalled. Here\\'s all the other car recalls this month you should know about\", \\'description\\': \\'Tesla (TSLA) issued its eighth Cybertruck recall last week, this time over faulty exterior panels that could become a road hazard. Read more...\\', \\'date\\': \\'2025-03-24T12:45:00Z\\'}]', tool_name='get_relevant_news', raw_input={'args': (), 'kwargs': {'stock_name': 'TSLA', 'date': '2025-04-09'}}, raw_output=[{'title': 'India Bars BYD Entry as Minister Signals Preference for Tesla, Citing Trade Concerns', 'description': 'India has denied market access to Chinese EV maker BYD over regulatory and geopolitical concerns.', 'date': '2025-04-08T15:10:57Z'}, {'title': \"Trump's auto tariffs will have a 'significant' impact on Tesla, Elon Musk says\", 'description': 'President Donald Trump’s new auto tariffs will have a “significant” effect on Tesla (TSLA), CEO Elon Musk says. Read more...', 'date': '2025-03-27T13:33:00Z'}, {'title': 'People are ditching their Teslas in huge numbers as the Elon Musk backlash grows', 'description': 'Tesla (TSLA) owners are ditching their vehicles in record numbers, as consumer interest in the brand appears to be waning.Read more...', 'date': '2025-03-21T16:30:00Z'}, {'title': 'Tesla just reported its worst quarterly sales in years as Elon Musk courts controversy', 'description': 'Tesla (TSLA) delivered slightly more than 336,000 electric vehicles between January and March, far below Wall Street’s already low expectationsRead more...', 'date': '2025-04-02T13:30:00Z'}, {'title': \"Nearly every Cybertruck has been recalled. Here's all the other car recalls this month you should know about\", 'description': 'Tesla (TSLA) issued its eighth Cybertruck recall last week, this time over faulty exterior panels that could become a road hazard. Read more...', 'date': '2025-03-24T12:45:00Z'}], is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "def max_price_diff(stock_name: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Get the date with the maximum price difference for a given stock.\n",
    "    Args:\n",
    "        stock_name: The name of the stock to analyze.\n",
    "    Returns:\n",
    "        A dictionary with the date and maximum price difference.\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(stock_name)\n",
    "    df = stock.history(period=\"1mo\")\n",
    "    max_diff = (df[\"Close\"] - df[\"Open\"]).max()\n",
    "    max_diff_date = (df[\"Close\"] - df[\"Open\"]).idxmax()\n",
    "    return {\"date\": str(max_diff_date.date()), \"max_diff\": max_diff}\n",
    "print(max_price_diff('AAPL'))\n",
    "\n",
    "def get_relevant_news(stock_name: str, date: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Get relevant news articles for a given stock and date.\n",
    "    Args:\n",
    "        stock_name: The name of the stock to analyze.\n",
    "        date: The date of the stock data.\n",
    "    Returns:\n",
    "        A list of relevant news articles.\n",
    "    \"\"\"\n",
    "    api_key = \"92d4b4314ea141caac845fbb91eb6b0a\" # ваш API ключ здесь!\n",
    "    api_template = \"https://newsapi.org/v2/everything?q={keyword}&apiKey={api_key}&from={date_from}\"\n",
    "    articles = requests.get(api_template.format(keyword=stock_name, api_key=api_key, date_from=\"2025-03-21\")).json()\n",
    "    filtered_articles = [{\"title\": el[\"title\"], \"description\": el[\"description\"], \"date\": el[\"publishedAt\"]} for el in articles[\"articles\"] if \n",
    "                         (el[\"title\"] != \"[Removed]\") \n",
    "                         and (el[\"publishedAt\"] <= date)]\n",
    "    return filtered_articles[:5]\n",
    "\n",
    "max_price_diff_llamaindex = FunctionTool.from_defaults(fn=max_price_diff)\n",
    "get_relevant_news_llamaindex = FunctionTool.from_defaults(fn=get_relevant_news)\n",
    "agent = ReActAgent(tools=[max_price_diff_llamaindex, get_relevant_news_llamaindex], llm=llm, memory=None, verbose=True)\n",
    "text = \"Can you help me? What happened to TSLA stock over the last month?\"\n",
    "agent.chat(text)\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AAdkMlz_oUGV",
   "metadata": {
    "id": "AAdkMlz_oUGV"
   },
   "source": [
    "# Smolagents sql agent - 10 баллов\n",
    "\n",
    "Теперь давайте познакомимся со smolagents - библиотекой, которая тоже позволяет писать код для агентов.\n",
    "\n",
    "Давайте попробуем написать агента для взаимодействия с БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HnMC6d6Kmx12",
   "metadata": {
    "id": "HnMC6d6Kmx12"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pGFFWVkepti8",
   "metadata": {
    "id": "pGFFWVkepti8"
   },
   "source": [
    "Наш агент будет работать с базой данных и выполнять задачу text2sql - ходить в базу данных за нас. Мы создадим базу данных с 2мя таблицами:\n",
    "1. Таблица A содержит id человека и его имя\n",
    "2. Таблица B содержит id человека и его работу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LDul0ChcpaBt",
   "metadata": {
    "id": "LDul0ChcpaBt"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('example.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('DROP TABLE IF EXISTS A')\n",
    "cursor.execute('DROP TABLE IF EXISTS B')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE A (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        username TEXT NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE B (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        job TEXT NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "user_data = [\n",
    "    (1, 'alice'),\n",
    "    (2, 'bob'),\n",
    "    (3, 'charlie'),\n",
    "    (4, 'dave'),\n",
    "    (5, 'eve'),\n",
    "    (6, 'frank'),\n",
    "    (7, 'grace'),\n",
    "    (8, 'heidi'),\n",
    "    (9, 'ivan'),\n",
    "    (10, 'judy'),\n",
    "]\n",
    "\n",
    "job_data = [\n",
    "    (1, 'engineer'),\n",
    "    (2, 'designer'),\n",
    "    (3, 'manager'),\n",
    "    (4, 'developer'),\n",
    "    (5, 'analyst'),\n",
    "    (6, 'engineer'),\n",
    "    (7, 'support'),\n",
    "    (8, 'engineer'),\n",
    "    (9, 'engineer'),\n",
    "    (10, 'marketing'),\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO A (id, username) VALUES (?, ?)', user_data)\n",
    "cursor.executemany('INSERT INTO B (id, job) VALUES (?, ?)', job_data)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KgUnk1PEp73C",
   "metadata": {
    "id": "KgUnk1PEp73C"
   },
   "source": [
    "Некоторые пользователи имеют одинаковые професии. Давайте попросим агента решить следующую задачу: найти самую популярную профессию и вывести имена всех людей, которые ей владеют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nf0a4HvHqmB_",
   "metadata": {
    "id": "nf0a4HvHqmB_"
   },
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\"\"\"\n",
    "Допиишите документацию, чтобы модель лучше работала можете сообщить ей о том,\n",
    "какие таблицы есть в бд и какие у них схемы.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def sql_engine(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "    Args:\n",
    "        query: ...\n",
    "\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    con = sqlite3.connect('example.db')\n",
    "    rows = con.execute(query)\n",
    "    for row in rows:\n",
    "        output += \"\\n\" + str(row)\n",
    "    return output\n",
    "\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JV6leXgXmVem",
   "metadata": {
    "id": "JV6leXgXmVem"
   },
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "\n",
    "model = HfApiModel()\n",
    "# ---- Ваш код здесь ----\n",
    "agent = CodeAgent # допишите конструктор\n",
    "# напишите промпт - агент должен найти самую популярную профессию и вывести имена людей, которые ей занимаются\n",
    "question = \"\"\n",
    "agent.run(question)\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y4yYHFqar_kS",
   "metadata": {
    "id": "Y4yYHFqar_kS"
   },
   "source": [
    "Самой популярной работой должен быть engineer, в ней заняты alice, frank, heidi, ivan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BsFpwpfgr-3w",
   "metadata": {
    "id": "BsFpwpfgr-3w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-0lygrEwmX8C",
   "metadata": {
    "id": "-0lygrEwmX8C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "multi_train",
   "language": "python",
   "name": "multi_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
