{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d481b105",
   "metadata": {
    "collapsed": true,
    "id": "d481b105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.16\n",
      "  Downloading langchain-0.3.16-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting langchain-core==0.3.32\n",
      "  Downloading langchain_core-0.3.32-py3-none-any.whl (412 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.4/412.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai==0.3.2\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-together==0.3.0\n",
      "  Downloading langchain_together-0.3.0-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-llms-together==0.2.0\n",
      "  Downloading llama_index_llms_together-0.2.0-py3-none-any.whl (2.1 kB)\n",
      "Collecting smolagents==1.13.0\n",
      "  Downloading smolagents-1.13.0-py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting together==1.5.5\n",
      "  Downloading together-1.5.5-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.51.3\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting pydantic==2.7.4\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (3.11.12)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.3.16)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.16)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain==0.3.16)\n",
      "  Downloading langsmith-0.3.32-py3-none-any.whl (358 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.2/358.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain==0.3.16) (9.0.0)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.32)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain-core==0.3.32) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langchain-core==0.3.32) (4.12.2)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai==0.3.2)\n",
      "  Downloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain-openai==0.3.2)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-llms-together==0.2.0)\n",
      "  Downloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai-like<0.3.0,>=0.2.0 (from llama-index-llms-together==0.2.0)\n",
      "  Downloading llama_index_llms_openai_like-0.2.0-py3-none-any.whl (3.1 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (0.29.2)\n",
      "Requirement already satisfied: rich>=13.9.4 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (13.9.4)\n",
      "Requirement already satisfied: jinja2>=3.1.4 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (3.1.5)\n",
      "Requirement already satisfied: pillow<11.2.0,>=11.0.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from smolagents==1.13.0) (11.1.0)\n",
      "Collecting markdownify>=0.14.1 (from smolagents==1.13.0)\n",
      "  Downloading markdownify-1.1.0-py3-none-any.whl (13 kB)\n",
      "Collecting duckduckgo-search>=6.3.7 (from smolagents==1.13.0)\n",
      "  Downloading duckduckgo_search-8.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting python-dotenv (from smolagents==1.13.0)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (8.1.8)\n",
      "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together==1.5.5)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (19.0.1)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (4.67.1)\n",
      "Requirement already satisfied: typer<0.16,>=0.9 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from together==1.5.5) (0.9.0)\n",
      "Collecting huggingface-hub>=0.28.0 (from smolagents==1.13.0)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from transformers==4.51.3) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from transformers==4.51.3) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from transformers==4.51.3) (0.5.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from pydantic==2.7.4) (0.7.0)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic==2.7.4)\n",
      "  Downloading pydantic_core-2.18.4-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.16) (1.18.3)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search>=6.3.7->smolagents==1.13.0)\n",
      "  Downloading primp-0.15.0-cp38-abi3-macosx_10_12_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml>=5.3.0 (from duckduckgo-search>=6.3.7->smolagents==1.13.0)\n",
      "  Downloading lxml-5.3.2-cp310-cp310-macosx_10_9_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.28.0->smolagents==1.13.0) (2024.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from jinja2>=3.1.4->smolagents==1.13.0) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.32) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.16)\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.16) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain==0.3.16)\n",
      "  Downloading orjson-3.10.16-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.16) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain==0.3.16)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-macosx_10_9_x86_64.whl (788 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.7/788.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (3.9.1)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.16)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (0.9.0)\n",
      "Collecting wrapt (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-macosx_10_9_x86_64.whl (38 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.0 (from llama-index-llms-openai-like<0.3.0,>=0.2.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from markdownify>=0.14.1->smolagents==1.13.0) (4.13.3)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from markdownify>=0.14.1->smolagents==1.13.0) (1.17.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (1.8.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (314 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.3.16) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from rich>=13.9.4->smolagents==1.13.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from rich>=13.9.4->smolagents==1.13.0) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.16) (3.1.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai==0.3.2) (1.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from beautifulsoup4<5,>=4.9->markdownify>=0.14.1->smolagents==1.13.0) (2.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.16) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.16) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents==1.13.0) (0.1.2)\n",
      "Requirement already satisfied: joblib in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (1.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/igorchebuniaev/Library/Caches/pypoetry/virtualenvs/synthetic-multinode-6dIUQGRd-py3.10/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0) (1.0.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-together==0.2.0)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: filetype, dirtyjson, zstandard, wrapt, tenacity, python-dotenv, pydantic-core, primp, orjson, marshmallow, lxml, jsonpatch, jiter, eval-type-backport, async-timeout, tiktoken, pydantic, markdownify, huggingface-hub, duckduckgo-search, deprecated, dataclasses-json, smolagents, openai, langsmith, transformers, together, llama-index-core, langchain-core, llama-index-llms-openai, langchain-text-splitters, langchain-openai, llama-index-llms-openai-like, langchain-together, langchain, llama-index-llms-together\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: orjson\n",
      "    Found existing installation: orjson 3.9.10\n",
      "    Uninstalling orjson-3.9.10:\n",
      "      Successfully uninstalled orjson-3.9.10\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.6\n",
      "    Uninstalling pydantic-2.10.6:\n",
      "      Successfully uninstalled pydantic-2.10.6\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.29.2\n",
      "    Uninstalling huggingface-hub-0.29.2:\n",
      "      Successfully uninstalled huggingface-hub-0.29.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic-yaml 1.3.0 requires importlib-metadata, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed async-timeout-4.0.3 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 duckduckgo-search-8.0.1 eval-type-backport-0.2.2 filetype-1.2.0 huggingface-hub-0.30.2 jiter-0.9.0 jsonpatch-1.33 langchain-0.3.16 langchain-core-0.3.32 langchain-openai-0.3.2 langchain-text-splitters-0.3.5 langchain-together-0.3.0 langsmith-0.3.32 llama-index-core-0.11.23 llama-index-llms-openai-0.2.16 llama-index-llms-openai-like-0.2.0 llama-index-llms-together-0.2.0 lxml-5.3.2 markdownify-1.1.0 marshmallow-3.26.1 openai-1.75.0 orjson-3.10.16 primp-0.15.0 pydantic-2.7.4 pydantic-core-2.18.4 python-dotenv-1.1.0 smolagents-1.13.0 tenacity-8.5.0 tiktoken-0.9.0 together-1.5.5 transformers-4.51.3 wrapt-1.17.2 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain==0.3.16 langchain-core==0.3.32 langchain-openai==0.3.2 langchain-together==0.3.0 llama-index-llms-together==0.2.0 smolagents==1.13.0 together==1.5.5 transformers==4.51.3 numpy pydantic==2.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ro4W8om8_c9R",
   "metadata": {
    "id": "Ro4W8om8_c9R"
   },
   "source": [
    "**После установки окружения, если возникает ошибка с numpy - перезапустите ноутбук.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610f8418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dff7c4",
   "metadata": {
    "id": "22dff7c4"
   },
   "source": [
    "# Tools and Agents\n",
    "В этом домашнем задании мы разберемся в том, как работают function calls, как их видит и обрабатывает модель и разберемся с несколькими популярными фреймворками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c44059",
   "metadata": {
    "id": "33c44059"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "import requests\n",
    "from together import Together\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619698e9",
   "metadata": {
    "id": "619698e9"
   },
   "source": [
    "# Function calls - 20 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A4I9HliFWlcz",
   "metadata": {
    "id": "A4I9HliFWlcz"
   },
   "source": [
    "## Клиент - 5 баллов\n",
    "\n",
    "В предыдущем задании мы разобрались с походами в API - мы ходили к провайдеру с помощью библиотеки requests и каждый раз собирали данные для посылки руками.\n",
    "\n",
    "Многие провайдеры предоставляют удобный интерфейс для взаимодействия ввиде библиотеки для python. Таки библиотеки есть и у [openai](https://platform.openai.com/docs/api-reference/responses/create) и у [Together](https://github.com/togethercomputer/together-python?tab=readme-ov-file#chat-completions). Многие провайдеры специально делают свой API совместимым с openai, например так сделал [deepseek](https://api-docs.deepseek.com/)\n",
    "\n",
    "\n",
    "Давайте познакомимся с Together клиентом в этом задании. Для этого давайте используем функцию `client.chat.completions.create`. Также давайте добавим опции сэмплинга, которые в этой функции поддержаны. Их можно посылать и в запросах через requests, но мы здесь и далее будем пользоваться клиентом.\n",
    "* top_k = 100\n",
    "* temperature = 0.5\n",
    "* top_p = 0.9\n",
    "* repetition_penalty = 1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f3931a",
   "metadata": {
    "id": "a3f3931a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Вставьте свой ключ из https://api.together.ai/\n",
    "# и не забудьте удалить его перед посылкой\n",
    "#или подайте его через переменную окружения\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "API_KEY = \"4b3c0ae4d2a4967007029571545378b611c58fdcdad808abb154b07fb0993ab7\"\n",
    "# ---- Конец кода ----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88dc9341",
   "metadata": {
    "id": "88dc9341"
   },
   "outputs": [],
   "source": [
    "client = Together(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e3ef8",
   "metadata": {
    "id": "b88e3ef8"
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of Britain?\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "# docs\n",
    "# https://github.com/togethercomputer/together-python?tab=readme-ov-file#chat-completions\n",
    "response = client.chat.completions.create # ваш код здесь\n",
    "\n",
    "response_text: str = ...\n",
    "# ---- Конец кода ----\n",
    "\n",
    "assert \"london\" in response_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IRlfNmmlk08u",
   "metadata": {
    "id": "IRlfNmmlk08u"
   },
   "source": [
    "## Structured output - 5 баллов\n",
    "\n",
    "На лекции мы узнали, что можно попросить модель напрямую сгенерировать структурированный выход несколькими способами:\n",
    "1. Попросить модель сгенерировать данные в нужном формате\n",
    "2. Использовать какой-либо алгоритм выбора токенов для соответствия заданной структуре.\n",
    "\n",
    "\n",
    "Давайте попробуем оба этих подхода.\n",
    "\n",
    "1. Попросите модель с помощью промптинга сгенерировать ингредиенты для какого-нибудь блюда\n",
    "2. Используйте для этой же задачи [structured output / constrained generation](https://docs.together.ai/docs/json-mode) с помощью Pydantic-классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m57YqNZxlcMc",
   "metadata": {
    "id": "m57YqNZxlcMc"
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "# в качестве блюда можно выбрать \"english breakfast\"\n",
    "\n",
    "# здесь составьте промпт в свободном формате\n",
    "response_freeform = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=...,\n",
    ")\n",
    "\n",
    "response_text: str = ...\n",
    "\n",
    "try:\n",
    "  json.loads(response_text)\n",
    "  print(\"В свободном формате получилось сгенерировать json\")\n",
    "except:\n",
    "  print(\"В свободном формате не получилось сгенерировать json, но это не ошибка, не нужно подгонять промпт\")\n",
    "\n",
    "# https://docs.together.ai/docs/json-mode\n",
    "class RecipeItem(BaseModel):\n",
    "  name: str = Field(description=...)\n",
    "  quantity: str = Field(description=...)\n",
    "\n",
    "class RecipeModel(BaseModel):\n",
    "    actionItems: list[...] = ...\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    "    response_format=...\n",
    ")\n",
    "response_text: str = ...\n",
    "\n",
    "try:\n",
    "  print(json.loads(response_text))\n",
    "  print(\"Успешно сгенерировался json в structured output\")\n",
    "except:\n",
    "  print(\"Здесь должен был сгенерироваться валидный json\")\n",
    "\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5758f",
   "metadata": {
    "id": "08d5758f"
   },
   "source": [
    "## Function Call pipeline - 10 баллов\n",
    "\n",
    "Давайте теперь посмотрим, как можно использовать tools в связке с моделями. У нас есть функция, которая входит в базу данных и получает информацию о юзере. Базы данных, конечно же, у нас никакой нет, но у нас есть некоторая функция, которая эмулирует это поведение, так что давайте попробуем ее описать.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5090a",
   "metadata": {
    "id": "2dd5090a"
   },
   "outputs": [],
   "source": [
    "def get_user_info_from_db(person_name: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Get a dictionary with information about person\n",
    "    Args:\n",
    "      person_name: Name of the person to look for\n",
    "    Returns:\n",
    "      Dictionary with information about person\n",
    "    \"\"\"\n",
    "    database = {\n",
    "        \"ilya\": {\n",
    "            \"job\": \"Software Developer\",\n",
    "            \"pets\": \"dog\",\n",
    "        },\n",
    "        \"farruh\": {\n",
    "            \"job\": \"Senior Data & Solution Architect\",\n",
    "            \"hobby\": \"travelling, hiking\",\n",
    "        },\n",
    "        \"timur\": {\n",
    "            \"job\": \"DeepSchool Founder\",\n",
    "            \"city\": \"Novosibirsk\",\n",
    "        }\n",
    "    }\n",
    "    no_info = {\"err\": f\"No info about {person_name}\"}\n",
    "    return database.get(person_name.lower(), no_info)\n",
    "\n",
    "print(get_user_info_from_db(\"Timur\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e8052",
   "metadata": {
    "id": "bf7e8052"
   },
   "source": [
    "Давайте попробуем описать эту функцию в формате json, чтобы модель могла ее увидеть!\n",
    "Заполните поля в определении дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3a3cf",
   "metadata": {
    "id": "dbb3a3cf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "get_user_info_from_db_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_user_info_from_db\",\n",
    "        \"description\": ..., # Напишите, что функция делает своими словами\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"person_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": ...# Опишите смысл аргумента\n",
    "                }\n",
    "            },\n",
    "            \"required\": [...] # укажите обязательные аргументы для функции\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e980a9be",
   "metadata": {
    "id": "e980a9be"
   },
   "source": [
    "Давайте пошлем наш запрос в модель. Для этого воспользуемся клиентом и функцией\n",
    "`client.chat.completions.create`. Не забудьте передать в поле tools список список из инструментов (список json).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdaebf",
   "metadata": {
    "id": "b2cdaebf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-7B-Instruct-Turbo\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "response = client.chat.completions.create # допишите вызов функции\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "\n",
    "assert len(response.choices[0].message.tool_calls) > 0\n",
    "\n",
    "print(response.choices[0].message.tool_calls)\n",
    "print()\n",
    "print(response.choices[0].message.tool_calls[0].function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b870a67",
   "metadata": {
    "id": "3b870a67"
   },
   "source": [
    "Если все хорошо, то мы получили ответ от модели со списком `response.choices[0].message.tool_calls`, который содержит в себе название функции и словарь с ее аргументами.\n",
    "\n",
    "Если бы мы не использовали клиент, то нам пришлось бы самим по правилам (регулярными выражениями) определять, что модель вызвала инструмент, но клиент берет эту работу за нас.\n",
    "\n",
    "Давайте теперь напишем код, который может с помощью значения tool_calls вызывать функцию с правильными аргументами.\n",
    "\n",
    "Здесь нам поможет FUNCTION_REGISTRY и то, что параметры в функцию можно передавать как словарь, например так\n",
    "```python\n",
    "def foo(a, b, c):\n",
    "    print(a, b, c)\n",
    "\n",
    "obj = {'b':10, 'c':'lee'}\n",
    "\n",
    "foo(100, **obj)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92feaf07",
   "metadata": {
    "id": "92feaf07"
   },
   "outputs": [],
   "source": [
    "from together.types.chat_completions import FunctionCall\n",
    "\n",
    "FUNCTION_REGISTRY = {\"get_user_info_from_db\": get_user_info_from_db}\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "\n",
    "def use_function_call(tool_call: FunctionCall):\n",
    "  # Ваш код здесь\n",
    "  # 1. Берем имя функции и по ней получаем функцию из FUNCTION_REGISTRY\n",
    "  # 2. Загружаем аргументы\n",
    "  # 3. Вызываем функцию с аргументами и возвращаем результат\n",
    "  ...\n",
    "\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "assert use_function_call(response.choices[0].message.tool_calls[0]) == get_user_info_from_db(\"Ilya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuh8culATfml",
   "metadata": {
    "id": "fuh8culATfml"
   },
   "source": [
    "Теперь давайте добавим ответ инструмента с ролью tool и сгенерируем моделью финальный ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y2vZpJlzTe-K",
   "metadata": {
    "id": "Y2vZpJlzTe-K"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "]\n",
    "# Давайте положим в историю диалога ответ инструмента с ролью tool\n",
    "messages.append(...)\n",
    "# вызовем новую генерацию\n",
    "response = client.chat.completions.create #\n",
    "response_text: str = ...\n",
    "# ---- Конец кода ----\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VqXB3KxLg-St",
   "metadata": {
    "id": "VqXB3KxLg-St"
   },
   "source": [
    "Теперь давайте посмотрим, как выглядел промпт на самом деле, для этого нужно использовать функцию `tokenizer.apply_chat_template` и в аргументе tools передать список функций, которые модель может использовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XN3dnJnpgb5s",
   "metadata": {
    "id": "XN3dnJnpgb5s"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B\")\n",
    "\n",
    "messages = [\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "{\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "]\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "full_prompt = tokenizer.apply_chat_template\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "print(full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907c917",
   "metadata": {
    "id": "e907c917"
   },
   "source": [
    "# Использование библиотек - 10 баллов\n",
    "\n",
    "Теперь, когда мы руками прошли весь пути обработки function call можно посмотреть уже на готовые инструменты.\n",
    "Мы много чего сделали руками:\n",
    "1. Писали описание функции\n",
    "2. Обрабатывали ответ\n",
    "3. Вызывали функцию\n",
    "4. Возвращали все это в модель\n",
    "\n",
    "Давайте теперь посмотрим, как оно работает в библиотеках!\n",
    "\n",
    "**NB** - библиотеки развиваются и вполне возможно, что к концу курса те интерфейсы, которые мы используем в этом домашнем задании будут уже неактуальны, но я уверен, что знаний и принципов, полученных из этих заданий хватит, чтобы адаптироваться к будущим вызовам!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b964f9",
   "metadata": {
    "id": "51b964f9"
   },
   "source": [
    "## LangChain - 5 баллов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef83e32",
   "metadata": {
    "id": "5ef83e32"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b08ae",
   "metadata": {
    "id": "0a7b08ae"
   },
   "source": [
    "Давайте ознакомимся с langchain-интеграцией together.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f75658",
   "metadata": {
    "id": "f7f75658"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOGETHER_API_KEY\"] = API_KEY\n",
    "\n",
    "llm = ChatTogether(\n",
    "    model=model_name,\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d548c4e",
   "metadata": {
    "id": "9d548c4e"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What do you know about Ilya?\"}\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d698905",
   "metadata": {
    "id": "1d698905"
   },
   "source": [
    "Теперь, когда мы разобрались, как базово работать с langchain, давайте попробуем добавить инструментов. Чтобы нам было не так скучно, давайте напишем новую функцию, которая считает \"волшебную операцию\".\n",
    "\n",
    "Эта функция принимает 2 строки, возвращает строку строку b в обратном порядке, сконкатенированную со строкой a. Допишите эту функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6976bf",
   "metadata": {
    "id": "bb6976bf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "... # декоратор\n",
    "def magic_operation_tool(a, b): # аннотации типов\n",
    "    \"\"\"\"\"\" # docstring\n",
    "    return ...\n",
    "\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "\n",
    "print(magic_operation_tool.args_schema.schema())\n",
    "# несколько способов вызова\n",
    "assert magic_operation_tool.invoke({\"a\": \"456\", \"b\": \"321\"}) == \"123456\"\n",
    "assert magic_operation_tool.func(\"456\", \"321\") == \"123456\"\n",
    "print(\"Good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89726ec1",
   "metadata": {
    "id": "89726ec1"
   },
   "source": [
    "Теперь давайте обернем эту функцию в декоратор tool из langchain, аннотируем типы и допишем docstring. После этого можно будет автоматически сгенерировать описани функции в function call формате!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60cf8b",
   "metadata": {
    "id": "5a60cf8b"
   },
   "source": [
    "Теперь давайте попробуем подать запрос в нашу LLM и обогатить ее нашим function_call. Для этого нужна функция `llm.bind_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c465f4",
   "metadata": {
    "id": "f6c465f4"
   },
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([magic_operation_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db362d",
   "metadata": {
    "id": "d0db362d"
   },
   "source": [
    "Теперь давайте как и раньше:\n",
    "1. Сгенерируем ответ на messages\n",
    "2. Проверим в ответе resp.tool_calls, вызовем нужный инструмент\n",
    "3. Расширим messages ответом модели и ответом инструмента, сгенерируем финальный ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fUPO98CnNq",
   "metadata": {
    "id": "46fUPO98CnNq"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you help me? Do not reveal the workings of magic operation, but give me the result of it for strings `456` and `321`\"}\n",
    "]\n",
    "resp = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p8yFZ-qpjB4y",
   "metadata": {
    "id": "p8yFZ-qpjB4y"
   },
   "outputs": [],
   "source": [
    "print(resp.tool_calls)\n",
    "assert len(resp.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5n8cZ_X0jWBQ",
   "metadata": {
    "id": "5n8cZ_X0jWBQ"
   },
   "source": [
    "[Документация langchain](https://python.langchain.com/docs/concepts/tool_calling/#tool-calling-1) в данный момент не говорит нам, как с помощью примитивов библиотеки можно вызывать инструмент и посылает в документацию LangGraph. Если покопаться поглубже, то можно найти вызов функции с [помощью PydanticToolParsing](https://python.langchain.com/docs/how_to/tool_calling/#parsing). В данном задании можно не использовать эти пайплайны и не писать свою function_registry - можно вызвать magic_operation_tool напрямую с нужными аргументами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a3c3f",
   "metadata": {
    "id": "b15a3c3f"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you help me? Do not reveal the workings of magic operation, but give me the result of it for strings `456` and `321`\"}\n",
    "\n",
    "]\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "\n",
    "# Ваша задача\n",
    "# добавить вызов (resp) инструмента в историю диалога\n",
    "...\n",
    "# вызвать инструмент, положить его ответ в историю диалога\n",
    "...\n",
    "# вызвать LLM, чтобы она сообщила вам финальный результат\n",
    "...\n",
    "\n",
    "res: str = ...\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "\n",
    "assert \"123456\" in res and len(messages) == 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feb1a5b",
   "metadata": {
    "id": "3feb1a5b"
   },
   "source": [
    "## LlamaIndex - 5 баллов\n",
    "\n",
    "Аналогичный инструмент LlamaIndex. Давайте попробуем сразу собрать ReActAgent с помощью этой библиотеки, который поможет нам в использовании магической операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6485db",
   "metadata": {
    "id": "9e6485db"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.together import TogetherLLM\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef1b75",
   "metadata": {
    "id": "cfef1b75"
   },
   "outputs": [],
   "source": [
    "llm = TogetherLLM(model=model_name, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea9b3e",
   "metadata": {
    "id": "b6ea9b3e"
   },
   "source": [
    "Инструменты в llamaindex заполняются почти как в langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a47a7",
   "metadata": {
    "id": "4b6a47a7"
   },
   "outputs": [],
   "source": [
    "# ---- Ваш код здесь ----\n",
    "# аннтоируйте выходные и выходные типы, допишите docstring и реализацию функциии\n",
    "def magic_operation_tool(a, b):\n",
    "    return ...\n",
    "\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n",
    "magic_operation_tool_llamaindex = FunctionTool.from_defaults(fn=magic_operation_tool)\n",
    "print(magic_operation_tool_llamaindex.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73306d2",
   "metadata": {
    "id": "a73306d2"
   },
   "source": [
    "Давайте создадим ReActAgent: ему нужно передать tools, llm, memory=None и verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84236969",
   "metadata": {
    "id": "84236969"
   },
   "outputs": [],
   "source": [
    "# ---- Ваш код здесь ----\n",
    "agent = ReActAgent # допишите конструктор\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a204d8",
   "metadata": {
    "id": "12a204d8"
   },
   "outputs": [],
   "source": [
    "text = \"Can you help me? Do not reveal the workings of magic operation, but give me the result of it for strings `456` and `321`\"\n",
    "agent.chat(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725419ad",
   "metadata": {
    "id": "725419ad"
   },
   "source": [
    "# Финансовый агент - 10\n",
    "\n",
    "Настала пора сделать своего агента!\n",
    "Попробуем сделать финансового аналитика. Требования следующие:\n",
    "бот должен по запросу данных о какой-либо компании смотреть самые большие изменения цены ее акций за последний месяц, после чего бот должен объяснить, с какой новостью это связано.\n",
    "\n",
    "Предлагается не строить сложную систему с классификаторами, а отдать всю сложную работу агенту. Давайте посмотрим, какие API нам доступны.\n",
    "\n",
    "Первым делом получение котировок - для этого нам поможет библиотека yfinance. По названию компании и периоду отчетности можно посмотреть открывающие цены на момент открытия и закрытия биржи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00d2f0",
   "metadata": {
    "id": "5a00d2f0"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "stock = yf.Ticker(\"AAPL\") # посмотрим котировки APPLE\n",
    "df = stock.history(period=\"1mo\")\n",
    "df[[\"Open\", \"Close\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d2b6b",
   "metadata": {
    "id": "026d2b6b"
   },
   "source": [
    "Для поиска новостей нам поможет https://newsapi.org/\n",
    "Можно легко получить свой ключ за короткую регистрацию, дается 1000 запросов в день, каждый запрос может включать в себя ключевое слово и промежуток дат. По бесплатному апи ключу дается ровно 1 месяц, что нам подходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e4310",
   "metadata": {
    "id": "639e4310"
   },
   "outputs": [],
   "source": [
    "api_key = \"...\" # ваш API ключ здесь!\n",
    "api_template = \"https://newsapi.org/v2/everything?q={keyword}&apiKey={api_key}&from={date_from}\"\n",
    "\n",
    "articles = requests.get(api_template.format(keyword=\"Apple\", api_key=api_key, date_from=\"2025-01-25\")).json()\n",
    "\n",
    "for article in articles[\"articles\"]:\n",
    "    if article[\"title\"] != \"[Removed]\":\n",
    "        print(article[\"title\"])\n",
    "        print(article[\"description\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f75126",
   "metadata": {
    "id": "32f75126"
   },
   "source": [
    "Очень много статей заблокированы и имеют название `[Removed]`, нужно их отфильтровать. В оставшихся статьях будем брать только title (заголовок) и description (описание или краткий пересказ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9378f6",
   "metadata": {
    "id": "cc9378f6"
   },
   "source": [
    "Вам необходимо реализовать [ReAct Agent](https://react-lm.github.io/). Особенность этого агента заключается в том, что он вначале формирует мысль, а потом вызывает действие (function call) для достижения какой-либо цели.\n",
    "\n",
    "Что нужно сделать:\n",
    "1. Описать и реализовать function call для определения, в какой день была самая большая разница в цене акций в момент открытия и закрытия биржи. Функция получает один аргумент - название акций компании (например AAPL для Apple), а выдает словарь с 2мя полями: с датой максимальной разницы в ценах и самой разницей в ценах.\n",
    "2. Описать и реализовать function call для получения 5 релевантных новостей о компании. В качестве аргумента принимаются название компании и дата. Ваша задача - сходить в newsapi, получить новости и вернуть 5 случайных новостей, которые произошли не позже чем день торгов. Если новостей меньше 5, то верните столько, сколько получится.\n",
    "3. После этого агент должен вернуть ответ, в котором постарается аргументировать изменения в цене.\n",
    "\n",
    "\n",
    "Реализовывать агента можно любым удобным способом, в том числе взять готовые имплементации.\n",
    "1. [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/agent/react_agent/) - вдобавок можно посмотреть предыдущее задание, где он уже используется.\n",
    "2. [Langchain/Langgraph](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#code)\n",
    "3. Написать полностью свою реализацию\n",
    "\n",
    "\n",
    "Не забудьте, что очень важно описать задачу в промпте: нужно сказать, какие цели у агента и что он должен сделать. У функций должны быть говорящие описания, чтобы LLM без лишних проблем поняла, какие есть функции и когда их использовать. По всем вопросам можно обращаться в наш телеграм-чат в канал \"Tools & Agents\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0dac5",
   "metadata": {
    "id": "a2b0dac5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AAdkMlz_oUGV",
   "metadata": {
    "id": "AAdkMlz_oUGV"
   },
   "source": [
    "# Smolagents sql agent - 10 баллов\n",
    "\n",
    "Теперь давайте познакомимся со smolagents - библиотекой, которая тоже позволяет писать код для агентов.\n",
    "\n",
    "Давайте попробуем написать агента для взаимодействия с БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HnMC6d6Kmx12",
   "metadata": {
    "id": "HnMC6d6Kmx12"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pGFFWVkepti8",
   "metadata": {
    "id": "pGFFWVkepti8"
   },
   "source": [
    "Наш агент будет работать с базой данных и выполнять задачу text2sql - ходить в базу данных за нас. Мы создадим базу данных с 2мя таблицами:\n",
    "1. Таблица A содержит id человека и его имя\n",
    "2. Таблица B содержит id человека и его работу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LDul0ChcpaBt",
   "metadata": {
    "id": "LDul0ChcpaBt"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('example.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('DROP TABLE IF EXISTS A')\n",
    "cursor.execute('DROP TABLE IF EXISTS B')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE A (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        username TEXT NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "    CREATE TABLE B (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        job TEXT NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "user_data = [\n",
    "    (1, 'alice'),\n",
    "    (2, 'bob'),\n",
    "    (3, 'charlie'),\n",
    "    (4, 'dave'),\n",
    "    (5, 'eve'),\n",
    "    (6, 'frank'),\n",
    "    (7, 'grace'),\n",
    "    (8, 'heidi'),\n",
    "    (9, 'ivan'),\n",
    "    (10, 'judy'),\n",
    "]\n",
    "\n",
    "job_data = [\n",
    "    (1, 'engineer'),\n",
    "    (2, 'designer'),\n",
    "    (3, 'manager'),\n",
    "    (4, 'developer'),\n",
    "    (5, 'analyst'),\n",
    "    (6, 'engineer'),\n",
    "    (7, 'support'),\n",
    "    (8, 'engineer'),\n",
    "    (9, 'engineer'),\n",
    "    (10, 'marketing'),\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO A (id, username) VALUES (?, ?)', user_data)\n",
    "cursor.executemany('INSERT INTO B (id, job) VALUES (?, ?)', job_data)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KgUnk1PEp73C",
   "metadata": {
    "id": "KgUnk1PEp73C"
   },
   "source": [
    "Некоторые пользователи имеют одинаковые професии. Давайте попросим агента решить следующую задачу: найти самую популярную профессию и вывести имена всех людей, которые ей владеют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nf0a4HvHqmB_",
   "metadata": {
    "id": "nf0a4HvHqmB_"
   },
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "\n",
    "# ---- Ваш код здесь ----\n",
    "\"\"\"\n",
    "Допиишите документацию, чтобы модель лучше работала можете сообщить ей о том,\n",
    "какие таблицы есть в бд и какие у них схемы.\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def sql_engine(query: str) -> str:\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "    Args:\n",
    "        query: ...\n",
    "\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    con = sqlite3.connect('example.db')\n",
    "    rows = con.execute(query)\n",
    "    for row in rows:\n",
    "        output += \"\\n\" + str(row)\n",
    "    return output\n",
    "\n",
    "# ---- Конец кода ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JV6leXgXmVem",
   "metadata": {
    "id": "JV6leXgXmVem"
   },
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "\n",
    "model = HfApiModel()\n",
    "# ---- Ваш код здесь ----\n",
    "agent = CodeAgent # допишите конструктор\n",
    "# напишите промпт - агент должен найти самую популярную профессию и вывести имена людей, которые ей занимаются\n",
    "question = \"\"\n",
    "agent.run(question)\n",
    "# ---- Конец кода ----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y4yYHFqar_kS",
   "metadata": {
    "id": "Y4yYHFqar_kS"
   },
   "source": [
    "Самой популярной работой должен быть engineer, в ней заняты alice, frank, heidi, ivan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BsFpwpfgr-3w",
   "metadata": {
    "id": "BsFpwpfgr-3w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-0lygrEwmX8C",
   "metadata": {
    "id": "-0lygrEwmX8C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "multi_train",
   "language": "python",
   "name": "multi_train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
